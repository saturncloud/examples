{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classification (single GPU)\n",
    "\n",
    "<img src=\"https://rapids.ai/assets/images/RAPIDS-logo-purple.svg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a machine learning training workflow using the famous [NYC Taxi Dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). That dataset contains information on taxi trips in New York City.\n",
    "\n",
    "In this exercise, you'll use `cudf` to load a subset of the data and `cuml` to answer this classification question:\n",
    "\n",
    "> based on characteristics that can be known at the beginning of a trip, will this trip result in a high tip?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RAPIDS libraries\n",
    "\n",
    "RAPIDS is a collection of libraries which enable you to take advantage of NVIDIA GPUs to accelerate machine learning workflows. This exercise uses the following RAPIDS package:\n",
    "    \n",
    "* `cudf`: data frame manipulation, similar to `pandas` and `numpy`\n",
    "* `cuml`: machine learning training and evaluation, similar to `scikit-learn`\n",
    "\n",
    "These libraries are already available in the `saturncloud/saturn-gpu` images by default. For more information on RAPIDS, see [\"Getting Started\"](https://rapids.ai/start.html) in the NVIDIA docs.\n",
    "\n",
    "### Monitoring GPU Usage\n",
    "\n",
    "This tutorial aims to teach you how to take advantage of the GPU for data science workflows. To prove to yourself that RAPIDS is utilizing the GPU, it's important to understand how to monitor that utilization while your code is running. If you already know how to do that, skip on to the next section.\n",
    "\n",
    "<details><summary>(click here to learn how to monitor resource utilization)</summary>\n",
    "\n",
    "**Monitoring CPU and Main Memory**\n",
    "    \n",
    "CPUs and GPUs are two different types of processors, and the GPU has its own dedicated memory. Many data science libraries that claim to offer GPU acceleration accomplish their tasks with a mix of CPU and GPU use, so it's important to monitor both to see what that code is doing.\n",
    "    \n",
    "To monitor CPU utilization and the amount of free main memory (memory available to the CPU), you can use `htop`.\n",
    "    \n",
    "Open a new terminal and run `htop`. That will keep an auto-updating dashboard up that shows the CPU utilization and memory usage.\n",
    "    \n",
    "**Monitoring GPU and GPU memory**\n",
    "    \n",
    "Open a new terminal and run the following command.\n",
    "    \n",
    "```shell\n",
    "watch -n 5 nvidia-smi\n",
    "```\n",
    "    \n",
    "This command will update the output in the terminal every 5 seconds. It shows some information like:\n",
    "    \n",
    "* current CUDA version\n",
    "* NVIDIA driver version\n",
    "* internal temperature\n",
    "* current utilization of GPU memory\n",
    "* list of processes (if any) currently running on the GPU, and how much GPU memory they're consuming\n",
    "    \n",
    "If you'd prefer a simpler view, you can also consider `gpustat`, which simply tracks temperature, GPU utilization, and memory. This is not available by default in the Saturn GPU images, but you can install it from PyPi.\n",
    "\n",
    "```shell\n",
    "pip install gpustat    \n",
    "```\n",
    "    \n",
    "And then run it\n",
    "    \n",
    "```shell\n",
    "gpustat -cp --watch\n",
    "```\n",
    "    \n",
    "Whichever option you choose, leave these terminals with the monitoring process running while you work, so you can see how the code below uses the avaiable resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Load data\n",
    "\n",
    "This example is designed to run quickly with small resources. So let's just load a single month of taxi data for training.\n",
    "\n",
    "The code below loads the data into a `cudf` data frame. This is similar to a `pandas` dataframe, but it lives in GPU memory and most operations on it are done on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "taxi = cudf.read_csv(\n",
    "    'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv',\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 7667792, Size: 1082.117204 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Num rows: {len(taxi)}, Size: {taxi.memory_usage(deep=True).sum() / 1e6} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df: cudf.DataFrame, target_col: str) -> cudf.DataFrame:\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    Use 32 bit precision for GPU processing\n",
    "    '''\n",
    "    numeric_feat = [\n",
    "        'pickup_weekday', \n",
    "        'pickup_hour', \n",
    "        'pickup_week_hour', \n",
    "        'pickup_minute', \n",
    "        'passenger_count',\n",
    "    ]\n",
    "    categorical_feat = [\n",
    "        'PULocationID', \n",
    "        'DOLocationID',\n",
    "    ]\n",
    "    features = numeric_feat + categorical_feat\n",
    "\n",
    "    # add target\n",
    "    df = df[df.fare_amount > 0]  # avoid divide-by-zero\n",
    "    df['tip_fraction'] = df.tip_amount / df.fare_amount\n",
    "    df[target_col] = (df['tip_fraction'] > 0.2)\n",
    "    \n",
    "    # add features\n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    \n",
    "    # drop unused columns\n",
    "    df = df[features + [target_col]].astype('float32').fillna(-1)\n",
    "    \n",
    "    # convert target to int32 for efficiency (it's just 0s and 1s)\n",
    "    df[target_col] = df[target_col].astype('int32')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'high_tip'\n",
    "taxi_train = prep_df(\n",
    "    df=taxi,\n",
    "    target_col=target_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4001782\n",
       "0    3656453\n",
       "Name: high_tip, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_train.high_tip.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_week_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>high_tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_weekday  pickup_hour  pickup_week_hour  pickup_minute  \\\n",
       "0             1.0          0.0              24.0           46.0   \n",
       "1             1.0          0.0              24.0           59.0   \n",
       "2             4.0         13.0             109.0           48.0   \n",
       "3             2.0         15.0              63.0           52.0   \n",
       "4             2.0         15.0              63.0           56.0   \n",
       "\n",
       "   passenger_count  PULocationID  DOLocationID  high_tip  \n",
       "0              1.0         151.0         239.0         1  \n",
       "1              1.0         239.0         246.0         0  \n",
       "2              3.0         236.0         236.0         0  \n",
       "3              5.0         193.0         193.0         0  \n",
       "4              5.0         193.0         193.0         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams==1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_seed is set\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from cuml.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 4.98 s, total: 17.8 s\n",
      "Wall time: 6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features = [c for c in taxi_train.columns if c!= target_col]\n",
    "\n",
    "_ = rfc.fit(\n",
    "    taxi_train[features],\n",
    "    taxi_train[target_col]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "with open(f'{MODEL_PATH}/random_forest_rapids.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(rfc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics on test set\n",
    "\n",
    "Use a different month for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test = cudf.read_csv(\n",
    "    s3.open('s3://nyc-tlc/trip data/yellow_tripdata_2019-02.csv', mode='rb'),\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    ")\n",
    "\n",
    "taxi_test = prep_df(taxi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.metrics import roc_auc_score\n",
    "\n",
    "preds = rfc.predict_proba(taxi_test[features])[1]\n",
    "roc_auc_score(taxi_test[y_col], preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
