{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost regression (multi-node with Dask)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal.svg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/69/XGBoost_logo.png\" width=\"300\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import cloudpickle\n",
    "import dask.dataframe as dd\n",
    "import dask_xgboost\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "from dask_saturn import SaturnCluster\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "    \n",
    "numeric_feat = [\n",
    "    'pickup_weekday',\n",
    "    'pickup_weekofyear',\n",
    "    'pickup_hour',\n",
    "    'pickup_week_hour',\n",
    "    'pickup_minute',\n",
    "    'passenger_count',\n",
    "]\n",
    "categorical_feat = [\n",
    "    'PULocationID',\n",
    "    'DOLocationID',\n",
    "]\n",
    "features = numeric_feat + categorical_feat\n",
    "y_col = 'tip_fraction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 3\n",
    "cluster = SaturnCluster(\n",
    "    n_workers=n_workers,\n",
    "    scheduler_size='medium',\n",
    "    worker_size='large',\n",
    "    nthreads=2\n",
    ")\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the dashboard (link above ^) and watch it when you execute some commands, you'll see which tasks are running across the cluster.\n",
    "\n",
    "If you created your cluster here in this notebook, it might take a few minutes for all your nodes to become available. You can run the chunk below to block until all nodes are ready.\n",
    "\n",
    ">**Pro tip**: Create and/or start your cluster from the \"Dask\" page in Saturn if you want to get a head start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.wait_for_workers(n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and feature engineering\n",
    "\n",
    "Load a sample from a single month for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = dd.read_csv(\n",
    "    's3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv',\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "    storage_options={'anon': True},\n",
    "    assume_missing=True,\n",
    ").sample(frac=0.3, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Num rows: {len(taxi)}, Size: {taxi.memory_usage(deep=True).sum().compute() / 1e6} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    df = df[df.fare_amount > 0]  # avoid divide-by-zero\n",
    "    df['tip_fraction'] = df.tip_amount / df.fare_amount\n",
    "    \n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.tpep_pickup_datetime.dt.weekofyear\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = df[features + [y_col]].astype(float).fillna(-1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "taxi_train = prep_df(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask performs computations in a [lazy manner](https://tutorial.dask.org/01x_lazy.html), so we persist the dataframe to perform data loading and feature processing once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "taxi_train = taxi_train.persist()\n",
    "_ = wait(taxi_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = dask_xgboost.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method='approx',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=8,\n",
    "    n_estimators=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = xgb_reg.fit(taxi_train[features], y=taxi_train[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MODEL_PATH}/xgboost_dask.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(xgb_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics on test set\n",
    "\n",
    "Use a different month for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test = dd.read_csv(\n",
    "    's3://nyc-tlc/trip data/yellow_tripdata_2019-02.csv',\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "    storage_options={'anon': True},\n",
    "    assume_missing=True,\n",
    ").sample(frac=0.01, replace=False)\n",
    "\n",
    "taxi_test = prep_df(taxi_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics functions in `dask_ml` can compute metrics on Dask collection like Dask Array and Dask DataFrame, so you never have to hold all of the test data in memory on the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_reg.predict(taxi_test[features])\n",
    "mean_squared_error(taxi_test[y_col], preds, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
