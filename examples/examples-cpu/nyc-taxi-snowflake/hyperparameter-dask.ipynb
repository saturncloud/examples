{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "## Dask cluster\n",
    "\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal.svg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "MODEL_PATH = 'models'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "    \n",
    "numeric_feat = [\n",
    "    'pickup_weekday', \n",
    "    'pickup_weekofyear', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count',\n",
    "]\n",
    "categorical_feat = [\n",
    "    'pickup_taxizone_id', \n",
    "    'dropoff_taxizone_id',\n",
    "]\n",
    "features = numeric_feat + categorical_feat\n",
    "y_col = 'tip_fraction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-11 20:24:18] INFO - dask-saturn | Cluster is ready\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1d351df6fd4d6793c5f8aa7e9ba3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SaturnCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "import time\n",
    "\n",
    "n_workers = 3\n",
    "cluster = SaturnCluster(n_workers=n_workers, scheduler_size='medium', worker_size='large', nthreads=2)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the dashboard (link above ^) and watch it when you execute some commands, you'll see which tasks are running across the cluster.\n",
    "\n",
    "If you created your cluster here in this notebook, it might take a few minutes for all your nodes to become available. You can run the chunk below to block until all nodes are ready.\n",
    "\n",
    ">**Pro tip**: Create and/or start your cluster from the \"Dask\" page in Saturn if you want to get a head start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "while len(client.scheduler_info()['workers']) < n_workers:\n",
    "    print('Waiting for workers, got', len(client.scheduler_info()['workers']))\n",
    "    time.sleep(30)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and feature engineering\n",
    "\n",
    "Load a sample from a single month for this exercise. Note we are loading the data with Dask now (`dd.read_csv` vs. `pd.read_csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import s3fs\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import snowflake.connector\n",
    "\n",
    "creds = yaml.full_load(open('/home/jovyan/snowflake_creds.yml'))\n",
    "\n",
    "# get connection info\n",
    "conn_info = {\n",
    "    'warehouse': 'COMPUTE_WH',\n",
    "    'database': 'NYC_TAXI',\n",
    "    'schema': 'PUBLIC',\n",
    "    **creds,\n",
    "}\n",
    "conn = snowflake.connector.connect(**conn_info)\n",
    "q = \"select DISTINCT(DATE(PICKUP_DATETIME)) as date from taxi_yellow\"\n",
    "cur = conn.cursor().execute(q)\n",
    "dates = cur.fetch_pandas_all()['DATE'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    pickup_taxizone_id,\n",
    "    dropoff_taxizone_id,\n",
    "    passenger_count,\n",
    "    DIV0(TIP_AMOUNT, FARE_AMOUNT) as TIP_FRACTION,\n",
    "    DAYOFWEEKISO(PICKUP_DATETIME) - 1 as PICKUP_WEEKDAY,\n",
    "    WEEKOFYEAR(PICKUP_DATETIME) as PICKUP_WEEKOFYEAR,\n",
    "    HOUR(PICKUP_DATETIME) as PICKUP_HOUR,\n",
    "    (PICKUP_WEEKDAY * 24) + PICKUP_HOUR as PICKUP_WEEK_HOUR,\n",
    "    MINUTE(PICKUP_DATETIME) as PICKUP_MINUTE\n",
    "FROM taxi_yellow\n",
    "WHERE\n",
    "    date(pickup_datetime) = %s\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@delayed\n",
    "def load(conn_info, query, day, frac=0.01):\n",
    "    # q = query % str(day)\n",
    "    conn = snowflake.connector.connect(**conn_info)\n",
    "    cur = conn.cursor().execute(query, str(day))\n",
    "    taxi = cur.fetch_pandas_all().sample(frac=0.01, replace=True)\n",
    "    taxi.columns = [x.lower() for x in taxi.columns]\n",
    "    return taxi\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "_dates = [x for x in dates if x is not None and x >= dt.date(2019, 1, 1) and x < dt.date(2019, 2, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "taxi = dd.from_delayed([load(conn_info, query, day) for day in _dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_train = taxi[features + [y_col]].astype(float).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_weekofyear</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_week_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_taxizone_id</th>\n",
       "      <th>dropoff_taxizone_id</th>\n",
       "      <th>tip_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28719</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129730</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.226667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113329</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61998</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180926</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pickup_weekday  pickup_weekofyear  pickup_hour  pickup_week_hour  \\\n",
       "28719              6.0                2.0          2.0             146.0   \n",
       "129730             6.0                2.0         15.0             159.0   \n",
       "113329             6.0                2.0         13.0             157.0   \n",
       "61998              6.0                2.0          9.0             153.0   \n",
       "180926             6.0                2.0         18.0             162.0   \n",
       "\n",
       "        pickup_minute  passenger_count  pickup_taxizone_id  \\\n",
       "28719            16.0              1.0               234.0   \n",
       "129730           14.0              1.0               262.0   \n",
       "113329           12.0              1.0               186.0   \n",
       "61998            18.0              1.0               164.0   \n",
       "180926            5.0              1.0               162.0   \n",
       "\n",
       "        dropoff_taxizone_id  tip_fraction  \n",
       "28719                  48.0      0.240000  \n",
       "129730                236.0      0.226667  \n",
       "113329                 48.0      0.000000  \n",
       "61998                 246.0      0.220000  \n",
       "180926                164.0      0.220000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the preprocessing and `GridSearchCV` classes from dask-ml, but still use the scikit-learn `ElasticNet` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from dask_ml.compose import ColumnTransformer\n",
    "from dask_ml.preprocessing import StandardScaler, DummyEncoder, Categorizer\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('categorize', Categorizer(columns=categorical_feat)),\n",
    "    ('onehot', DummyEncoder(columns=categorical_feat)),\n",
    "    ('scale', ColumnTransformer(transformers=[('num', StandardScaler(), numeric_feat)])),\n",
    "    ('clf', ElasticNet(normalize=False, max_iter=100)),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'clf__l1_ratio': np.arange(0, 1.1, 0.1),\n",
    "    'clf__alpha': [0, 0.5, 1, 2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, cv=3, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up the Dask dashboard after you run the cell below, you'll see the grid search in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 411 ms, sys: 28.5 ms, total: 440 ms\n",
      "Wall time: 28.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.021441720427451495"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_ = grid_search.fit(taxi_train[features], taxi_train[y_col])\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0, 'clf__l1_ratio': 0.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "`GridSearchCV` automatically fits the best paramemters to the full data and stores in `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "with open(f'{MODEL_PATH}/elastic_net_dask.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(grid_search.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics on test set\n",
    "\n",
    "Use a different month for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "_dates = [x for x in dates if x is not None and x >= dt.date(2019, 2, 1) and x < dt.date(2019, 3, 1)]\n",
    "taxi_test = dd.from_delayed([load(conn_info, query, day) for day in _dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test = taxi_test.persist()\n",
    "_ = wait(taxi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.871446346944487"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "preds = grid_search.predict(taxi_test[features])\n",
    "mean_squared_error(taxi_test[y_col], preds, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
