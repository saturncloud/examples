{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21a962b-b3f8-49c6-bca9-6d07d3c5cb4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T17:33:22.602911Z",
     "iopub.status.busy": "2022-01-25T17:33:22.602324Z",
     "iopub.status.idle": "2022-01-25T17:33:25.666206Z",
     "shell.execute_reply": "2022-01-25T17:33:25.665688Z",
     "shell.execute_reply.started": "2022-01-25T17:33:22.602827Z"
    },
    "tags": []
   },
   "source": [
    "# Create Rolling Averages with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d3726-027e-4c04-ae8b-717683685472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T17:33:22.602911Z",
     "iopub.status.busy": "2022-01-25T17:33:22.602324Z",
     "iopub.status.idle": "2022-01-25T17:33:25.666206Z",
     "shell.execute_reply": "2022-01-25T17:33:25.665688Z",
     "shell.execute_reply.started": "2022-01-25T17:33:22.602827Z"
    },
    "tags": []
   },
   "source": [
    "> I need to calculate a rolling average of a numerical column, in time series data. In pandas, I can do this with rolling(x).mean() with sorted values, but what do I do in Dask, with distributed data?\n",
    "\n",
    "This example will walk you through performing rolling average calculations with data that is distributed over a Dask cluster. We'll use New York City taxi trip data and get the 30-day rolling average of base fare prices for our example.\n",
    "\n",
    "First, start the Dask cluster associated with your Saturn Cloud resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b4299-f93d-441f-9a42-46d4aca332b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(SaturnCluster())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e7f9e-8c67-4cd0-adf4-1d082addb1c5",
   "metadata": {},
   "source": [
    "After running the above command, it's recommended that you check on the Saturn Cloud resource page that the Dask cluster as fully online before continuing. Alternatively, you can use the command `client.wait_for_workers(3)` to halt the notebook execution until all three of the workers are ready.\n",
    "\n",
    "Now load your data into a Dask DataFrame. Here we are loading data for parquet file located in a public location hosted by Saturn Cloud. Using `read_parquet` from Dask takes the same form as using that function from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4bb88-37cc-4b8a-bb9d-b476102b133a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "taxi = dd.read_parquet(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-01.parquet\",\n",
    "    storage_options={\"anon\": True},\n",
    ").sample(frac=0.1, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2886561-f4be-481d-95c1-82997a609ae9",
   "metadata": {},
   "source": [
    "For the DataFrame we are calling function `set_index` to set `tpep_pickup_datetime` columns as the index. This will sort data by index within and across partitions. At this point, data and labels are lazy collections. They wonâ€™t be read into the workers' memory until some other computation asks for them. Hence, before we pass this data to other tasks we will call `persist()`. This will ensure that loading of data is run only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baefab-6733-4b41-abc0-63a89d645fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxi = taxi.set_index(\"tpep_pickup_datetime\")\n",
    "taxi = taxi.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b608b5-7289-4983-b619-417b47b027ce",
   "metadata": {},
   "source": [
    "In code below we get the 30-day rolling average of base fare prices ie. on column `fare_amount` and convert the resulting series to DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f4e2a-1eda-429e-be99-6e268cac24b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rolling_fares = taxi.fare_amount.rolling(\"30D\").mean()\n",
    "rolling_fares_df = rolling_fares.to_frame(name=\"fare_amount_rolled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65607a-5629-434a-a876-b5fda59334c4",
   "metadata": {},
   "source": [
    "We then join the original DataFrame `taxi` with DataFrame `rolling_fares_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa5203-6f48-4cf3-9a5a-3630569b1204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxi_new = taxi.join(rolling_fares_df, how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e4e3c-3bba-49ce-9f90-17f775701ae7",
   "metadata": {},
   "source": [
    "The rolling average computation is now complete. This is how the first few lines of rolling average look like in `taxi_new` DataFrame!\n",
    "\n",
    "![rolling avg](https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/rolling-amont.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
