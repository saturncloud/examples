{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21a962b-b3f8-49c6-bca9-6d07d3c5cb4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T17:33:22.602911Z",
     "iopub.status.busy": "2022-01-25T17:33:22.602324Z",
     "iopub.status.idle": "2022-01-25T17:33:25.666206Z",
     "shell.execute_reply": "2022-01-25T17:33:25.665688Z",
     "shell.execute_reply.started": "2022-01-25T17:33:22.602827Z"
    },
    "tags": []
   },
   "source": [
    "# Create Rolling Averages with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d3726-027e-4c04-ae8b-717683685472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T17:33:22.602911Z",
     "iopub.status.busy": "2022-01-25T17:33:22.602324Z",
     "iopub.status.idle": "2022-01-25T17:33:25.666206Z",
     "shell.execute_reply": "2022-01-25T17:33:25.665688Z",
     "shell.execute_reply.started": "2022-01-25T17:33:22.602827Z"
    },
    "tags": []
   },
   "source": [
    "> \"I need to calculate a rolling average of a numerical column, in time series data. In pandas, I can do this with rolling(x).mean() with sorted values, but what do I do in Dask, with distributed data?\"\n",
    "\n",
    "This example will walk you through performing rolling average calculations with data that is distributed over a Dask cluster. We'll use New York City taxi trip data, and get the 30-day rolling average of base fare prices, for our example.\n",
    "\n",
    "First, start the Dask cluster associated with your Saturn Cloud resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b4299-f93d-441f-9a42-46d4aca332b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(SaturnCluster())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e7f9e-8c67-4cd0-adf4-1d082addb1c5",
   "metadata": {},
   "source": [
    "After running the above command, it's recommend that you check on the Saturn Cloud resource page that the Dask cluster as fully online before continuing. Alternatively, you can use the command `client.wait_for_workers(3)` to halt the notebook execution until all three of the workers are ready.\n",
    "\n",
    "Now load your data into a Dask Dataframe. Here we are loading data for csv file located at s3 storage. Using read_csv from Dask takes the same form as using that function from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4bb88-37cc-4b8a-bb9d-b476102b133a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "taxi = dd.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    ").sample(frac=0.1, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2886561-f4be-481d-95c1-82997a609ae9",
   "metadata": {},
   "source": [
    "For dataframe we are calling function `set_index` to set `tpep_pickup_datetime` columns as the index. This will sort data by index within and across partitions. At this point, data and labels are lazy collections. They wonâ€™t be read into the workers' memory until some other computation asks for them. Hence, before we pass this data to other tasks we will call `presist()`. This will ensure that loading of data is run only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baefab-6733-4b41-abc0-63a89d645fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import wait\n",
    "\n",
    "taxi = taxi.set_index(\"tpep_pickup_datetime\")\n",
    "taxi = taxi.persist()\n",
    "_ = wait(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b608b5-7289-4983-b619-417b47b027ce",
   "metadata": {},
   "source": [
    "In code below we get the 30-day rolling average of base fare prices ie. on column `fare_amount` and convert the resulting series to DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f4e2a-1eda-429e-be99-6e268cac24b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rolling_fares = taxi.fare_amount.rolling(\"30D\").mean()\n",
    "rolling_fares_df = rolling_fares.to_frame(name=\"fare_amount_rolled\")\n",
    "type(rolling_fares_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65607a-5629-434a-a876-b5fda59334c4",
   "metadata": {},
   "source": [
    "We then join the original dataframe `taxi` with dataframe `rolling_fares_df`. Notice the new dataframe shows rolling averages in column `fare_amount_rolled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa5203-6f48-4cf3-9a5a-3630569b1204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxi_new = taxi.join(rolling_fares_df, how=\"outer\")\n",
    "taxi_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e4e3c-3bba-49ce-9f90-17f775701ae7",
   "metadata": {},
   "source": [
    "You can see that now we have a new column `fare_amount_rolled` added to dataframe. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
