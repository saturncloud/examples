{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0f87d4",
   "metadata": {},
   "source": [
    "## Dask Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10e8ae",
   "metadata": {},
   "source": [
    "Dask arrays are similar to NumPy arrays, however they are distributed across a Dask cluster. They mimics the functionality of NumPy arrays using a distributed backend requiring minimal changes to your code. This example walks through using a Dask array on Saturn Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb0b03",
   "metadata": {},
   "source": [
    "![dask-array](https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/dask-array.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2cda8",
   "metadata": {},
   "source": [
    "First, start the Dask cluster associated with your Saturn Cloud resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b93ee-6c7b-46a9-acfc-9273a2b90151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(SaturnCluster())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a07fe",
   "metadata": {},
   "source": [
    "After running the above command, it's recommend that you check on the Saturn Cloud resource page that the Dask cluster as fully online before continuing. Alternatively, you can use the command `client.wait_for_workers(3)` to halt the notebook execution until all three of the workers are ready.\n",
    "\n",
    "## Create a Dask Array from a NumPy Array\n",
    "\n",
    "Function `from_array` allows us to create a Dask array from array like structures. In code below we are creating a Dask array out of NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "y = da.from_array(\n",
    "    np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]), chunks=(2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ecb70",
   "metadata": {},
   "source": [
    "In code above, parameter `chunks` is telling us how to create blocks for this array. In this case we have created 4 blocks of equal size 2x2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baea1f7",
   "metadata": {},
   "source": [
    "## Create a Dask Array directly\n",
    "\n",
    "We can also create a Dask Array without using NumPy as an intermediary. In the code below a Dask Array is being created with all ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cbafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = da.ones((4, 4), chunks=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c63e6",
   "metadata": {},
   "source": [
    "## Create Dask Array from a Dask DataFrame\n",
    "\n",
    "Dask Arrays can be converted to and from Dask DataFrames. Here we are using method `to_dask_array`, to convert a Dask DataFrame to a Dask Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d3dde-0ca4-4fcc-a38a-4592d543e54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.dataframe import from_pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([{\"x\": 1, \"y\": 2, \"z\": 3}, {\"x\": 4, \"y\": 5, \"z\": 6}])\n",
    "df1 = from_pandas(df, npartitions=1)\n",
    "x = df1.to_dask_array()\n",
    "x.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2e2c3",
   "metadata": {},
   "source": [
    "## Example: Concatinating the array, slicing the array and finding mean of that sliced portion\n",
    "\n",
    "In code below we take two of the arrays created above and concatenate them. The result is slices and the mean is computed for that portion. Due to Daskâ€™s lazy evaluation, these arrays will not be computed until we explicitly ask Dask to perform the computation. Hence in the end of all the functions we add `compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c926a540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "da.concatenate([y, z], axis=0)[1:].mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c603a",
   "metadata": {},
   "source": [
    "## Best Practices:\n",
    "\n",
    "1. If possible, use NumPy arrays for as long your computations are fast enough and you data fits into a single machine.\n",
    "2. Choose the chunk dimensions which are small enough to fit in memory but are big enough to avoid large overheads during operations. \n",
    "3. Choose the shape of chunk wisely--if you are creating a Dask array out of HDF file which has chunks of dimensions 64x32 then you should create Dask array chunks in multiples of those dimensions.\n",
    "\n",
    "For more tips and tricks of using Dask check the [Saturn Cloud Blog](https://saturncloud.io/blog/dask-for-beginners/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
