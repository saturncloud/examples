{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3fb6bdf-29d3-4879-bcb0-d74da5071c0a",
   "metadata": {},
   "source": [
    "# Dask Futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e8418-e1e2-4899-9df2-0b29f550096c",
   "metadata": {},
   "source": [
    "Dask Futures allows you to use the syntax of the standard Python `concurrent.futures` library but to have the computations run across a distributed cluster of machines. It's an alternative to Dask Delayed which has its own particular syntax and lazy evaluation--here everything mimics the built in Python methods.\n",
    "\n",
    "This example will show how to have Python code run in parallel using Dask Futures. This will use a Formula One lap time dataset from [kaggle](https://www.kaggle.com/rohanrao/formula-1-world-championship-1950-2020?select=lap_times.csv). We will be finding a range of lap times for a formula one driver. First we create a pandas dataframe out of csv file and filter out data for a particular driver. We create three functions: finding maximum lap time, finding minimum lap time and then getting the range out of these two functions.  \n",
    "\n",
    "First, start the Dask cluster associated with your Saturn Cloud resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0cf1c9-1b45-4ce9-b4c0-9f2303828ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(SaturnCluster())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad3ae8",
   "metadata": {},
   "source": [
    "After running the above command, it's recommend that you check on the Saturn Cloud resource page that the Dask cluster as fully online before continuing. Alternatively, you can use the command `client.wait_for_workers(3)` to halt the notebook execution until all three of the workers are ready.\n",
    "\n",
    "Next, we load the data, filter it, and define the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39558b-824d-4710-8f1c-c4e59844d086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f1 = pd.read_csv(\n",
    "    \"s3://saturn-public-data/examples/Dask/f1_laptime.csv\", storage_options={\"anon\": True}\n",
    ")\n",
    "\n",
    "d_20 = f1[f1[\"driverId\"] == 20]\n",
    "\n",
    "\n",
    "def max_lap(x):\n",
    "    return max(x)\n",
    "\n",
    "\n",
    "def min_lap(x):\n",
    "    return min(x)\n",
    "\n",
    "\n",
    "def range_lap(a, b):\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677c60c-9bcc-4821-8c17-643edf9560f9",
   "metadata": {},
   "source": [
    "Now let us add scalability to code above using Futures.  We have 3 tasks below , finding the maximum laptime, minimum laptime and range. We have used future's submit method, to submit each task individually. `client.submit` allows us to submit data or tasks directly to the cluster. This method returns a future object and the results stay in remote thread. To convert Future into a concrete value you call result method as shown in last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc97f6a-52ea-4b28-ae96-bc277eff0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = client.submit(max_lap, d_20.milliseconds)\n",
    "b = client.submit(min_lap, d_20.milliseconds)\n",
    "c = client.submit(range_lap, a, b)\n",
    "c.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
