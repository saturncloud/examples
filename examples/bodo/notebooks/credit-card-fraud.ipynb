{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acoustic-camping",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection With Machine Learning in Python\n",
    "\n",
    "This example shows use of classification to help credit card company to detect potential fraud cases. \n",
    "Original example can be found [here](https://medium.com/codex/credit-card-fraud-detection-with-machine-learning-in-python-ac7281991d87)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-mongolia",
   "metadata": {},
   "source": [
    "### Notes on running this example:\n",
    "\n",
    "By defaults runs use Bodo. Hence, data is distributed in chunks across processes.\n",
    "\n",
    "To run the code:\n",
    "1. Make sure you [add your AWS account credentials to Saturn Cloud](https://saturncloud.io/docs/examples/python/load-data/qs-load-data-s3/#create-aws-credentials) to access the data.\n",
    "2. If you want to run the example using pandas only (without Bodo):\n",
    "    1. Comment lines magic expression (`%%px`) and bodo decorator (`@bodo.jit`) from all the code cells.\n",
    "    2. Then, re-run cells from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275bd502-c7df-4693-ad91-32abacc66be8",
   "metadata": {},
   "source": [
    "### Start an IPyParallel cluster\n",
    "Run the following code in a cell to start an IPyParallel cluster. 4 cores are used in this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85ae9e-883f-454c-a860-a9ab05065133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "import psutil\n",
    "\n",
    "n = min(psutil.cpu_count(logical=False), 8)\n",
    "rc = ipp.Cluster(engines=\"mpi\", n=n).start_and_connect_sync(activate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f272c-f965-4764-bdba-d643bf6e6515",
   "metadata": {},
   "source": [
    "### Verifying your setup\n",
    "Run the following code to verify that your IPyParallel cluster is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c4772-a044-468b-851a-dc4672e07f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import bodo\n",
    "\n",
    "print(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-enzyme",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - Numpy to work with arrays\n",
    " - scikit-learn to build and evaluate classification models\n",
    " - xgboost for xgboost classifier model algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import time\n",
    "\n",
    "import bodo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random forest tree algorithm\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression algorithm\n",
    "from sklearn.metrics import accuracy_score  # evaluation metric\n",
    "from sklearn.model_selection import train_test_split  # data split\n",
    "from sklearn.preprocessing import StandardScaler  # data normalization\n",
    "from sklearn.svm import LinearSVC  # SVM classification algorithm\n",
    "from xgboost import XGBClassifier  # XGBoost algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-daughter",
   "metadata": {},
   "source": [
    "## Data Processing and EDA\n",
    "1. Load dataset\n",
    "2. Compute the percentage of fraud cases in the overall recorded transcations.\n",
    "3. Get a statistical view of both fraud and non-fraud transaction amount data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"df\"], cache=True)\n",
    "def load_data():\n",
    "    start = time.time()\n",
    "    df = pd.read_csv(\"s3://bodo-example-data/creditcard/creditcard.csv\")\n",
    "    df.drop(\"Time\", axis=1, inplace=True)\n",
    "    end = time.time()\n",
    "    print(\"Read Time: \", (end - start))\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536465d-7b0f-421d-8204-42db1446eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def data_processing(df):\n",
    "    cases = len(df)\n",
    "    nonfraud_cases = df[df.Class == 0]\n",
    "    fraud_cases = df[df.Class == 1]\n",
    "    nonfraud_count = len(nonfraud_cases)\n",
    "    fraud_count = len(fraud_cases)\n",
    "    fraud_percentage = round(fraud_count / nonfraud_count * 100, 2)\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Total number of cases are \", cases)\n",
    "    print(\"Number of Non-fraud cases are \", nonfraud_count)\n",
    "    print(\"Number of fraud cases are\", fraud_count)\n",
    "    print(\"Percentage of fraud cases is \", fraud_percentage)\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"NON-FRAUD CASE AMOUNT STATS\")\n",
    "    print(nonfraud_cases.Amount.describe())\n",
    "    print(\"FRAUD CASE AMOUNT STATS\")\n",
    "    print(fraud_cases.Amount.describe())\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "\n",
    "data_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-mathematics",
   "metadata": {},
   "source": [
    "## Feature Selection & Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-directory",
   "metadata": {},
   "source": [
    "### 1. Normalize `Amount` variable\n",
    "`Amount` variable varies when compared to the rest of the variables. To reduce its range of values, we normalize it using the `StandardScaler` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"df\"], cache=True)\n",
    "def sc(df):\n",
    "    start = time.time()\n",
    "    sc = StandardScaler()\n",
    "    amount = df[\"Amount\"].values\n",
    "    amount = amount.reshape(-1, 1)\n",
    "    sc.fit(amount)\n",
    "    df[\"Amount\"] = (sc.transform(amount)).ravel()\n",
    "    print(\"StandardScaler time: \", time.time() - start)\n",
    "    print(df[\"Amount\"].head(10))\n",
    "\n",
    "\n",
    "sc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-viking",
   "metadata": {},
   "source": [
    "### 2. Split the data into a training set and testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"df\", \"X_train\", \"X_test\", \"y_train\", \"y_test\"], cache=True)\n",
    "def data_split(df):\n",
    "    X = df.drop(\"Class\", axis=1).values\n",
    "    y = df[\"Class\"].values.astype(np.int64)\n",
    "    start = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, train_size=0.8, random_state=0\n",
    "    )\n",
    "    print(\"train_test_split time: \", time.time() - start)\n",
    "    print(\"X_train samples :\", X_train[:1])\n",
    "    print(\"X_test samples :\", X_test[0:1])\n",
    "    print(\"y_train samples :\", y_train[0:20])\n",
    "    print(\"y_test samples :\", y_test[0:20])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-antarctica",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Here we have built four different types of classification models and evaluate these models using accuracy score metrics provided by scikit-learn package.\n",
    "\n",
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"], cache=True)\n",
    "def lr_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_yhat = lr.predict(X_test)\n",
    "    print(\"LogisticRegression fit and predict time: \", time.time() - start)\n",
    "    print(\n",
    "        \"Accuracy score of the Logistic Regression model is {}\".format(\n",
    "            accuracy_score(y_test, lr_yhat)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "lr_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-lawrence",
   "metadata": {},
   "source": [
    "#### 2. Random Forest Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"], cache=True)\n",
    "def rf_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    rf = RandomForestClassifier(max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_yhat = rf.predict(X_test)\n",
    "    print(\"RandomForestClassifier fit and predict time: \", time.time() - start)\n",
    "    print(\n",
    "        \"Accuracy score of the Random Forest Tree model is {}\".format(\n",
    "            accuracy_score(y_test, rf_yhat)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "rf_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-stamp",
   "metadata": {},
   "source": [
    "#### 3. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-stress",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"], cache=True)\n",
    "def xgb_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    xgb = XGBClassifier(max_depth=4)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_yhat = xgb.predict(X_test)\n",
    "    print(\"XGBClassifier fit and predict time: \", time.time() - start)\n",
    "    print(\n",
    "        \"Accuracy score of the XGBoost model is {}\".format(\n",
    "            accuracy_score(y_test, xgb_yhat)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "xgb_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-jones",
   "metadata": {},
   "source": [
    "#### 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"], cache=True)\n",
    "def lsvc_model(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    lsvc = LinearSVC(random_state=42)\n",
    "    lsvc.fit(X_train, y_train)\n",
    "    lsvc_yhat = lsvc.predict(X_test)\n",
    "    print(\"LinearSVC fit and predict time: \", time.time() - start)\n",
    "    print(\n",
    "        \"Accuracy score of the Linear Support Vector Classification model is {}\".format(\n",
    "            accuracy_score(y_test, lsvc_yhat)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "lsvc_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-house",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To stop the cluster run the following command.\n",
    "rc.cluster.stop_cluster_sync()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
