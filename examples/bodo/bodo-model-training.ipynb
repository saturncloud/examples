{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conservative-ghost",
   "metadata": {},
   "source": [
    "# Single-Node Bodo - Jupyter Notebook\n",
    "\n",
    "This example shows how to do feature engineering and train models using the HPC-like platform Bodo using a notebook on a single node.\n",
    "New York taxi data is used to predict how much a tip each driver will get. Both the feature engineering\n",
    "and model training are parallelized across multiple cores using Bodo. This can be a straightforward way to\n",
    "make Python code run faster that it would otherwise without requiring much change to the code.\n",
    "\n",
    "The Bodo framework knows when to parallelize code based on the `%%px` at the start of cells and `@bodo.jit` function decorators. Removing those and restarting the kernel will run the code without Bodo.\n",
    "\n",
    "**The Bodo parallel cluster in this example runs within the same Saturn Cloud resource as the notebook itself.** Thus, to increase the performance of the Bodo cluster you only need to increase the instance size of the Jupyter Server resource its running on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f302f-c922-4942-874e-b0a6787022f2",
   "metadata": {},
   "source": [
    "## Start an IPyParallel cluster\n",
    "\n",
    "Run the following code in a cell to start an IPyParallel cluster. IPyParallel is used to interactively control a cluster of IPython processes. The variable `n` is used to specify the number of clusters based on the number of CPU cores availble (up to 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0050c46a-4484-40f4-9aed-5ebccfb5abab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "import psutil\n",
    "\n",
    "n = min(psutil.cpu_count(logical=False), 8)\n",
    "\n",
    "# command to create and start the local cluster\n",
    "rc = ipp.Cluster(engines=\"mpi\", n=n).start_and_connect_sync(activate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f5e9e-78f1-4be3-940a-3fb2b2132927",
   "metadata": {},
   "source": [
    "The following code imports bodo and verifies that the IPyParallel cluster is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73c63c-ce82-4d0c-9ecd-8d8b1cf5ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import bodo\n",
    "\n",
    "print(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-asset",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - scikit-learn to build and evaluate regression models\n",
    " - xgboost for xgboost regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import time\n",
    "\n",
    "import bodo\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-director",
   "metadata": {},
   "source": [
    "## Load and clean data\n",
    "\n",
    "The function below will load the taxi data from a public S3 bucket into a single pandas DataFrame.\n",
    "\n",
    "\n",
    ">**Note**: Bodo works best for very large datasets, so downloading the data used in the examples can take some time. Please be patient while the datasets download for each example - you will see the speed benefits of Bodo when manipulating the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"taxi\"], cache=True)\n",
    "def get_taxi_trips():\n",
    "    start = time.time()\n",
    "    taxi = pd.read_csv(\n",
    "        \"s3://bodo-example-data/nyc-taxi/yellow_tripdata_2019.csv\",\n",
    "        parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    )\n",
    "    print(\"Reading time: \", time.time() - start)\n",
    "    print(taxi.head())\n",
    "    print(taxi.shape)\n",
    "    return taxi\n",
    "\n",
    "\n",
    "taxi = get_taxi_trips()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-cherry",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "The data is then modified to have a set of features appropriate for machine learning. Besides\n",
    "the Bodo decorators this is the same function you would use for training without Bodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"taxi_df\", \"df\"], cache=True)\n",
    "def prep_df(taxi_df):\n",
    "    \"\"\"\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    df = taxi_df[taxi_df.fare_amount > 0][\n",
    "        \"tpep_pickup_datetime\", \"passenger_count\", \"tip_amount\", \"fare_amount\"\n",
    "    ].copy()  # avoid divide-by-zero\n",
    "    df[\"tip_fraction\"] = df.tip_amount / df.fare_amount\n",
    "\n",
    "    df[\"pickup_weekday\"] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df[\"pickup_weekofyear\"] = df.tpep_pickup_datetime.dt.weekofyear\n",
    "    df[\"pickup_hour\"] = df.tpep_pickup_datetime.dt.hour\n",
    "    df[\"pickup_week_hour\"] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df[\"pickup_minute\"] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = (\n",
    "        df[\n",
    "            \"pickup_weekday\",\n",
    "            \"pickup_weekofyear\",\n",
    "            \"pickup_hour\",\n",
    "            \"pickup_week_hour\",\n",
    "            \"pickup_minute\",\n",
    "            \"passenger_count\",\n",
    "            \"tip_fraction\",\n",
    "        ]\n",
    "        .astype(float)\n",
    "        .fillna(-1)\n",
    "    )\n",
    "    print(\"Data preparation time: \", time.time() - start)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "taxi_feat = prep_df(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34125c50",
   "metadata": {},
   "source": [
    "The data is then split into X and y sets as well as training and testing using the scikit-learn functions. Again bodo is used to increase the speed at which it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"taxi_feat\", \"X_train\", \"X_test\", \"y_train\", \"y_test\"])\n",
    "def data_split(taxi_feat):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        taxi_feat[\n",
    "            \"pickup_weekday\",\n",
    "            \"pickup_weekofyear\",\n",
    "            \"pickup_hour\",\n",
    "            \"pickup_week_hour\",\n",
    "            \"pickup_minute\",\n",
    "            \"passenger_count\",\n",
    "        ],\n",
    "        taxi_feat[\"tip_fraction\"],\n",
    "        test_size=0.3,\n",
    "        train_size=0.7,\n",
    "        random_state=42,\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(taxi_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-surprise",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "\n",
    "Below we'll train four distinct linear models on the data, all using Bodo for faster performance.\n",
    "We'll train the models to predict the `tip_fraction` variable and evaluate these models against the test set using RMSE.\n",
    "\n",
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"], cache=True)\n",
    "def lr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    lr = LinearRegression()\n",
    "    lr_fitted = lr.fit(X_train, y_train)\n",
    "    print(\"Linear Regression fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    lr_preds = lr_fitted.predict(X_test)\n",
    "    print(\"Linear Regression prediction time: \", time.time() - start)\n",
    "    print(mean_squared_error(y_test, lr_preds, squared=False))\n",
    "\n",
    "\n",
    "lr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-julian",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"])\n",
    "def rr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    rr = Ridge()\n",
    "    rr_fitted = rr.fit(X_train, y_train)\n",
    "    print(\"Ridge fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    rr_preds = rr_fitted.predict(X_test)\n",
    "    print(\"Ridge prediction time: \", time.time() - start)\n",
    "    print(mean_squared_error(y_test, rr_preds, squared=False))\n",
    "\n",
    "\n",
    "rr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-session",
   "metadata": {},
   "source": [
    "#### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-winning",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"])\n",
    "def lsr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    lsr = Lasso()\n",
    "    lsr_fitted = lsr.fit(X_train, y_train)\n",
    "    print(\"Lasso fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    lsr_preds = lsr_fitted.predict(X_test)\n",
    "    print(\"Lasso prediction time: \", time.time() - start)\n",
    "    print(mean_squared_error(y_test, lsr_preds, squared=False))\n",
    "\n",
    "\n",
    "lsr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-evolution",
   "metadata": {},
   "source": [
    "#### SGD regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"X_train\", \"y_train\", \"X_test\", \"y_test\"])\n",
    "def sgdr_model(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    sgdr = SGDRegressor(max_iter=100, penalty=\"l2\")\n",
    "    sgdr_fitted = sgdr.fit(X_train, y_train)\n",
    "    print(\"SGDRegressor fitting time: \", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    sgdr_preds = sgdr_fitted.predict(X_test)\n",
    "    print(\"SGDRegressor prediction time: \", time.time() - start)\n",
    "    print(mean_squared_error(y_test, sgdr_preds, squared=False))\n",
    "\n",
    "\n",
    "sgdr_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9413a73",
   "metadata": {},
   "source": [
    "## Stopping the cluster\n",
    "\n",
    "When you're done using the parallel cluster you can shut it down with a single command. Note that since the cluster is running within the same Jupyter Server resource as the notebook, there is no change to what hardware is running after you stop it (since the resource is still one). Thus in this case there isn't a need to shut it off unless you wish to reset the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-hindu",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# command to stop the cluster\n",
    "rc.cluster.stop_cluster_sync()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
