{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Prefect Cloud with Saturn Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/dask.png\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/prefect.png\" width=\"150\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "This notebook contains sample code to take a `prefect` flow and distribute its work with a `Dask` cluster. This is similar to `01-prefect.ipynb` with one important addition: instead of deploying the flow as a Saturn Cloud deployment, this notebook describes how to register a flow with [Prefect Cloud](https://www.prefect.io/cloud/) so that service can be used for orchestrating when the flow runs.\n",
    "\n",
    "**NOTE**: This notebook assumes that you have already done the following:\n",
    "* created a Prefect Cloud account\n",
    "* set up the appropriate credentials in Saturn\n",
    "* set up a Prefect Cloud agent in Saturn Cloud\n",
    "\n",
    "Details on these prerequisites can be found in [\"Using Prefect Cloud with Saturn Cloud\"](https://www.saturncloud.io/docs/examples/prefect/prefect_cloud/).\n",
    "\n",
    "The flow below mocks the process of measuring the effectiveness of a deployed statistical model.\n",
    "\n",
    "### Model Details\n",
    "\n",
    "The data used for this example is the **\"Incident management process enriched event log\"** dataset [from the UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log).That dataset contains tickets from an IT support system, including characteristics like the priority of the ticket, the time it was opened, and the time it was closed.\n",
    "\n",
    "This dataset can be used to solve a regression task:\n",
    "\n",
    "> Given the characteristics of a ticket, how long will it be until it is closed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "The code in this notebook uses `prefect` for orchestration *(figuring out what to do, and in what order)* and `dask` for execution *(doing the things)*.\n",
    "\n",
    "It relies on the following additional non-builtin libraries:\n",
    "\n",
    "* `numpy`: data manipulation\n",
    "* `pandas`: data manipulation\n",
    "* `requests`: read in data from the internet\n",
    "* `scikit-learn`: evaluation metric functions\n",
    "* `dask-saturn`: create and interact with Saturn Cloud `Dask` clusters ([link](https://github.com/saturncloud/dask-saturn))\n",
    "* `prefect-saturn`: register Prefect flows with both Prefect Cloud and have them run on Saturn Cloud Dask clusters ([link](https://github.com/saturncloud/prefect-saturn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import prefect\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from io import BytesIO\n",
    "from prefect import task, Parameter, Flow\n",
    "from prefect.schedules import IntervalSchedule\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from prefect_saturn import PrefectCloudIntegration\n",
    "\n",
    "PREFECT_CLOUD_PROJECT_NAME = os.environ[\"PREFECT_CLOUD_PROJECT_NAME\"]\n",
    "SATURN_USERNAME = os.environ[\"SATURN_USERNAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate with Prefect Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!prefect auth login -t ${PREFECT_USER_TOKEN}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Create a Prefect Cloud Project\n",
    "\n",
    "Prefect Cloud organizes flows within workspaces called \"projects\". Before you can register a flow with Prefect Cloud, it's necessary to create a project if you don't have one yet.\n",
    "\n",
    "The code below will create a new project in whatever Prefect Cloud tenant you're authenticated with. If that project already exists, this code does not have any side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = prefect.Client()\n",
    "client.create_project(project_name=PREFECT_CLOUD_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Define Tasks\n",
    "\n",
    "`prefect` refers to a workload as a \"flow\", which comprises multiple individual things to do called \"tasks\". From [the Prefect docs](https://docs.prefect.io/core/concepts/tasks.html):\n",
    "\n",
    "> A task is like a function: it optionally takes inputs, performs an action, and produces an optional result.\n",
    "\n",
    "The goal of this notebooks flow is to evaluate, on an ongoing basis, the performance of a model that predicts time-to-close for tickets in an IT support system.\n",
    "\n",
    "That can be broken down into the following tasks\n",
    "\n",
    "* `get_trial_id()`: assign a unique ID to each run\n",
    "* `get_ticket_data_batch()`: get a random set of newly-closed tickets\n",
    "* `get_target()`: given a batch of tickets, compute how long it took to close them\n",
    "* `predict()`: predict the time-to-close, using the heuristic \"higher-priority tickets close faster\"\n",
    "* `evaluate_model()`: compute evaluation metrics comparing predicted and actual time-to-close\n",
    "* `get_trial_summary()`: collect all evaluation metrics in one object\n",
    "* `write_trial_summary()`: write trial results somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def get_trial_id() -> str:\n",
    "    \"\"\"\n",
    "    Generate a unique identifier for this trial.\n",
    "    \"\"\"\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "@task\n",
    "def get_ticket_data_batch(batch_size: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate the experience of getting a random sample of new tickets\n",
    "    from an IT system, to test the performance of a model.\n",
    "    \"\"\"\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00498/incident_event_log.zip\"\n",
    "    resp = requests.get(url)\n",
    "    zipfile = ZipFile(BytesIO(resp.content))\n",
    "    data_file = \"incident_event_log.csv\"\n",
    "    # _date_parser has to be a lambda or pandas won't convert dates correctly\n",
    "    _date_parser = lambda x: pd.NaT if x == \"?\" else datetime.strptime(x, \"%d/%m/%Y %H:%M\")\n",
    "    df = pd.read_csv(\n",
    "        zipfile.open(data_file),\n",
    "        parse_dates=[\"opened_at\", \"resolved_at\", \"closed_at\", \"sys_created_at\", \"sys_updated_at\"],\n",
    "        infer_datetime_format=False,\n",
    "        converters={\n",
    "            \"opened_at\": _date_parser,\n",
    "            \"resolved_at\": _date_parser,\n",
    "            \"closed_at\": _date_parser,\n",
    "            \"sys_created_at\": _date_parser,\n",
    "            \"sys_updated_at\": _date_parser,\n",
    "        },\n",
    "        na_values=[\"?\"],\n",
    "    )\n",
    "    df[\"sys_updated_at\"] = pd.to_datetime(df[\"sys_updated_at\"])\n",
    "    rows_to_score = np.random.randint(0, df.shape[0], 100)\n",
    "    return df.iloc[rows_to_score]\n",
    "\n",
    "\n",
    "@task\n",
    "def get_target(df):\n",
    "    \"\"\"\n",
    "    Compute time-til-close on a data frame of tickets\n",
    "    \"\"\"\n",
    "    time_til_close = (df[\"closed_at\"] - df[\"sys_updated_at\"]) / np.timedelta64(1, \"s\")\n",
    "    return time_til_close\n",
    "\n",
    "\n",
    "@task\n",
    "def predict(df):\n",
    "    \"\"\"\n",
    "    Given an input data frame, predict how long it will be until the ticket is closed.\n",
    "    For simplicity, using a super simple model that just says\n",
    "    \"high-priority tickets get closed faster\".\n",
    "    \"\"\"\n",
    "    seconds_in_an_hour = 60.0 * 60.0\n",
    "    preds = df[\"priority\"].map(\n",
    "        {\n",
    "            \"1 - Critical\": 6.0 * seconds_in_an_hour,\n",
    "            \"2 - High\": 24.0 * seconds_in_an_hour,\n",
    "            \"3 - Moderate\": 120.0 * seconds_in_an_hour,\n",
    "            \"4 - Lower\": 240.0 * seconds_in_an_hour,\n",
    "        }\n",
    "    )\n",
    "    default_guess_for_no_priority = 180.0 * seconds_in_an_hour\n",
    "    preds = preds.fillna(default_guess_for_no_priority)\n",
    "    return preds\n",
    "\n",
    "\n",
    "@task\n",
    "def evaluate_model(y_true, y_pred, metric_name: str) -> float:\n",
    "    metric_func_lookup = {\n",
    "        \"mae\": mean_absolute_error,\n",
    "        \"medae\": median_absolute_error,\n",
    "        \"mse\": mean_squared_error,\n",
    "        \"r2\": r2_score,\n",
    "    }\n",
    "    metric_func = metric_func_lookup[metric_name]\n",
    "    return metric_func(y_true, y_pred)\n",
    "\n",
    "\n",
    "@task\n",
    "def get_trial_summary(trial_id: str, actuals, input_df: pd.DataFrame, metrics: dict) -> dict:\n",
    "    out = {\"id\": trial_id}\n",
    "    out[\"data\"] = {\n",
    "        \"num_obs\": input_df.shape[0],\n",
    "        \"metrics\": metrics,\n",
    "        \"target\": {\n",
    "            \"mean\": actuals.mean(),\n",
    "            \"median\": actuals.median(),\n",
    "            \"min\": actuals.min(),\n",
    "            \"max\": actuals.max(),\n",
    "        },\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "@task(log_stdout=True)\n",
    "def write_trial_summary(trial_summary: str):\n",
    "    \"\"\"\n",
    "    Write out a summary of the file. Currently just logs back to the\n",
    "    Prefect logger\n",
    "    \"\"\"\n",
    "    logger = prefect.context.get(\"logger\")\n",
    "    logger.info(json.dumps(trial_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Construct a Flow\n",
    "\n",
    "Now that all of the task logic has been defined, the next step is to compose those tasks into a \"flow\". From [the Prefect docs](https://docs.prefect.io/core/concepts/flows.html):\n",
    "\n",
    "> A Flow is a container for Tasks. It represents an entire workflow or application by describing the dependencies between tasks.\n",
    "\n",
    "> Flows are DAGs, or \"directed acyclic graphs.\" This is a mathematical way of describing certain organizational principles:\n",
    "\n",
    "> * A graph is a data structure that uses \"edges\" to connect \"nodes.\" Prefect models each Flow as a graph in which Task dependencies are modeled by Edges.\n",
    "> * A directed graph means that edges have a start and an end: when two tasks are connected, one of them unambiguously runs first and the other one runs second.\n",
    "> * An acyclic directed graph has no circular dependencies: if you walk through the graph, you will never revisit a task you've seen before.\n",
    "\n",
    "Because we want this job to run on a schedule, the code below provides one additional argument to `Flow()`, a special \"schedule\" object. In this case, the code below says \"run this flow once every 24 hours\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = IntervalSchedule(interval=timedelta(hours=24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: `prefect` flows do not have to be run on a schedule. To test a single run, just omit `schedule` from the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(f\"{SATURN_USERNAME}-ticket-model-evaluation\", schedule=schedule) as flow:\n",
    "    batch_size = Parameter(\"batch-size\", default=1000)\n",
    "    trial_id = get_trial_id()\n",
    "\n",
    "    # pull sample data\n",
    "    sample_ticket_df = get_ticket_data_batch(batch_size)\n",
    "\n",
    "    # compute target\n",
    "    actuals = get_target(sample_ticket_df)\n",
    "\n",
    "    # get prediction\n",
    "    preds = predict(sample_ticket_df)\n",
    "\n",
    "    # compute evaluation metrics\n",
    "    mae = evaluate_model(actuals, preds, \"mae\")\n",
    "    medae = evaluate_model(actuals, preds, \"medae\")\n",
    "    mse = evaluate_model(actuals, preds, \"mse\")\n",
    "    r2 = evaluate_model(actuals, preds, \"r2\")\n",
    "\n",
    "    # get trial summary in a string\n",
    "    trial_summary = get_trial_summary(\n",
    "        trial_id=trial_id,\n",
    "        input_df=sample_ticket_df,\n",
    "        actuals=actuals,\n",
    "        metrics={\"MAE\": mae, \"MedAE\": medae, \"MSE\": mse, \"R2\": r2},\n",
    "    )\n",
    "\n",
    "    # store trial summary\n",
    "    trial_complete = write_trial_summary(trial_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have all of the work defined in tasks and arranged within a flow, but none of the tasks have run yet. In the next section, we'll do that using `Dask`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Register with Prefect Cloud\n",
    "\n",
    "Now that the business logic of the flow is complete, we can add information that Saturn will need to know to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration = PrefectCloudIntegration(prefect_cloud_project_name=PREFECT_CLOUD_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run `register_flow_with_saturn().\n",
    "\n",
    "`register_flow_with_saturn()` does a few important things:\n",
    "    \n",
    "* specifies how and where the flow's code is stored so it can be retrieved by a Prefect Cloud agent (see `flow.storage`)\n",
    "* specifies the infrastructure needed to run the flow. In this case, it uses a `KubernetesJobEnvironment` with a Saturn Dask cluster (see `flow.environment`)\n",
    "    \n",
    "The code below also customizes the Dask cluster used when executing the flow.\n",
    "\n",
    "* `n_workers = 3`: use 3 workers\n",
    "* `worker_size =\"xlarge\"`: each worker has 2 CPU cores and 16 GB RAM\n",
    "    - **NOTE**: you can find the full list of sizes with `prefect_saturn.describe_sizes()`\n",
    "* `autoclose = False`: leave the Dask cluster running after the flow run finishes\n",
    "* `worker_is_spot = False`: don't use spot instances for workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = integration.register_flow_with_saturn(\n",
    "    flow=flow,\n",
    "    dask_cluster_kwargs={\n",
    "        \"n_workers\": 3,\n",
    "        \"worker_size\": \"xlarge\",\n",
    "        \"scheduler_size\": \"medium\",\n",
    "        \"autoclose\": False,\n",
    "        \"worker_is_spot\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step necessary is to \"register\" the flow with Prefect Cloud. If this is the first time you've registered this flow, it will create a new flow in Prefect Cloud under the project in `PREFECT_CLOUD_PROJECT_NAME`. If you already have a flow in this project with this name, it will create a new version of it in Prefect Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.register(project_name=PREFECT_CLOUD_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Run the flow\n",
    "\n",
    "You shouldn't have to do anything to run the flow. Now that Prefect Cloud has it, it will be run once every 24 hours. You can confirm this by doing all of the following:\n",
    "\n",
    "* If you are an admin, go to the \"Logs\" page in Saturn Cloud and look at the Prefect Cloud Agent running the flow\n",
    "* Go to the \"Dask\" page in Saturn Cloud. You should see that a new Dask cluster has been created to run this flow\n",
    "* Go to Prefect Cloud. If you navigate to this flow and click \"Runs\", you should see task statuses and and logs for this flow\n",
    "\n",
    "If you want to run the flow immediately, navigate to the flow in the Prefect Cloud UI and click \"Quick Run\", or open a terminal and run the code below.\n",
    "\n",
    "```shell\n",
    "prefect auth login -t ${PREFECT_USER_TOKEN}\n",
    "prefect run flow \\\n",
    "    --name ${SATURN_USERNAME}-ticket-model-evaluation \\\n",
    "    --project ${PREFECT_CLOUD_PROJECT_NAME}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In this tutorial, you learned how to use infrastructure from Saturn Cloud to run `prefect` flows orchestrated by Prefect Cloud.\n",
    "\n",
    "Try changing the code above and re-running the flow. Add logging, add new tasks, or [customize the Dask cluster](https://github.com/saturncloud/prefect-saturn#customize-dask).\n",
    "\n",
    "If you have existing prefect flows, try running one of them on Saturn using this notebook as a template.\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
