{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce78932",
   "metadata": {},
   "source": [
    "# Training using Single GPU\n",
    "\n",
    "[Tensorflow](https://rapids.ai/) is a popular, powerful framework for deep learning used by data scientists across industries.\n",
    "\n",
    "In this example, you'll train Resnet50 architecture to identify different species of birds. This dataset constitutes 40,000+ birds and has been taken from [kaggle](https://www.kaggle.com/gpiosenka/100-bird-species).\n",
    "\n",
    "\n",
    "First we import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cd78e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e3b5e",
   "metadata": {},
   "source": [
    "We will be using [Weights & Biases](https://wandb.ai/site) to monitor GPU performance. Users will need to set their own Saturn Cloud env credential for wandb. Check the Saturn Cloud [example on Weights & Biases](https://saturncloud.io/docs/examples/python/weights-and-biases/qs-wandb/) on more information on creating and connecting W&B account to Saturn Cloud. First, we log into Weights & Biases. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d4326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874cd0fd",
   "metadata": {},
   "source": [
    "### Extracting Data\n",
    "The dataset originally had 285 classes. We have taken subset of this data which has 61 classes. The data is stored in AWS S3. The first time you run this job, you'll need to download the training and test data which will be saved at path `dataset/birds/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedb346-9132-4deb-9e07-2ae904943992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "_ = s3.get(\n",
    "    rpath=\"s3://saturn-public-data/100-bird-species/100-bird-species/*/*/*.jpg\",\n",
    "    lpath=\"dataset/birds/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d38b8",
   "metadata": {},
   "source": [
    "Run the code below to ensure that TensorFlow just uses memory as needed, instead of using all the RAM it has access to on your GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1f23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75217f72",
   "metadata": {},
   "source": [
    "### Training\n",
    "In code below we are constructing Keras data object for training and validation set using `keras.preprocessing.image_dataset_from_directory`. We have chosen Adam optimizer and have set learning rate to 0.02.  We are training our classifier with ResNet50 architecture, which has 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer. The model is being compiled, trained and saved at path `model/keras_single/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c2f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_fit(n_epochs, base_lr, batchsize, classes):\n",
    "\n",
    "    model = tf.keras.applications.ResNet50(include_top=True, weights=None, classes=classes)\n",
    "\n",
    "    # --------- Start wandb --------- #\n",
    "    wandb.init(config=wbargs, project=\"wandb_saturn_demo\")\n",
    "\n",
    "    # Data\n",
    "    train_ds = (\n",
    "        tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"dataset/birds/train\", image_size=(224, 224), batch_size=batchsize\n",
    "        )\n",
    "        .prefetch(2)\n",
    "        .cache()\n",
    "        .shuffle(1000)\n",
    "    )\n",
    "\n",
    "    valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        \"dataset/birds/valid\", image_size=(224, 224), batch_size=batchsize\n",
    "    ).prefetch(2)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=base_lr)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    start = time.time()\n",
    "\n",
    "    model.fit(train_ds, epochs=n_epochs, validation_data=valid_ds, callbacks=[WandbCallback()])\n",
    "    end = time.time() - start\n",
    "    print(\"model training time\", end)\n",
    "    wandb.log({\"training_time\": end})\n",
    "\n",
    "    # Close your wandb run\n",
    "    wandb.run.finish()\n",
    "\n",
    "    tf.keras.models.save_model(model, \"model/keras_single/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6631bcc",
   "metadata": {},
   "source": [
    "In the code below we are setting up the necessary parameters . We are only running 2 epochs to save time, but once you've got this working you'll have all the information you need to build and run bigger TensorFlow models on Saturn Cloud. A single GPU processes all our batches every epoch. All the model parameters, as well as some extra elements like Notes and Tags are tracked by Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596ad2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = {\"n_epochs\": 2, \"base_lr\": 0.02, \"classes\": 285, \"batchsize\": 64}\n",
    "\n",
    "wbargs = {\n",
    "    **model_params,\n",
    "    \"Notes\": \"tf_v100_2x\",\n",
    "    \"Tags\": [\"single\", \"gpu\", \"tensorflow\"],\n",
    "    \"dataset\": \"Birds\",\n",
    "    \"architecture\": \"ResNet50\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b40bf2",
   "metadata": {},
   "source": [
    "Now run the model training process and save your trained model object to the Jupyter instance memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc494ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tester = train_model_fit(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c8e6a-d729-41d5-909f-8a945b00e47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
