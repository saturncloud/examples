{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RAPIDS on a single GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same machine learning exercise as the previous notebook, except on a cluster of multiple GPUs with Dask. This exercise uses the following RAPIDS packages:\n",
    "    \n",
    "* [`dask-cudf`](https://docs.rapids.ai/api/cudf/stable/dask-cudf.html): distributed `cudf` dataframes using Dask\n",
    "* [`cuml.dask`](https://github.com/rapidsai/cuml): distributed `cuml` algorithms using Dask\n",
    "\n",
    "## Connect to Dask Cluster\n",
    "\n",
    "This project has a Dask cluster defined for it, which you can start or connect to in the below cell. For more information about Dask clusters in Saturn Cloud, check out [the docs](https://www.saturncloud.io/docs/examples/dask/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "\n",
    "n_workers = 3\n",
    "cluster = SaturnCluster(n_workers=n_workers)\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The code below loads the data into a `dask-cudf` data frame. This is similar to a `pandas` or `cudf` dataframe, but it is distributed across GPUs in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_cudf\n",
    "\n",
    "taxi = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many dataframe operations that you would execute on a `pandas` dataframe also work for a `dask-cudf` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we say that a `dask-cudf` dataframe is a *distributed* data frame, that means that it comprises multiple smaller `cudf` data frames. Run the following to see how many of these pieces (called \"partitions\") there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Cast to 32-bit types for compatibility with older versions of `cuml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = taxi[[\"PULocationID\", \"DOLocationID\", \"passenger_count\"]].astype(\"float32\").fillna(-1)\n",
    "y = (taxi[\"tip_amount\"] > 1).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask performs computations in a [lazy manner](https://tutorial.dask.org/01x_lazy.html), so we persist the dataframe to perform data loading and feature processing and load into GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = client.persist([X, y])\n",
    "_ = wait(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics\n",
    "We'll use another month of taxi data for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-02.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")\n",
    "\n",
    "X_test = taxi_test[[\"PULocationID\", \"DOLocationID\", \"passenger_count\"]].astype(\"float32\").fillna(-1)\n",
    "y_test = (taxi_test[\"tip_amount\"] > 1).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.metrics import roc_auc_score\n",
    "\n",
    "preds = rfc.predict_proba(X_test)[1]\n",
    "roc_auc_score(y_test.compute(), preds.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
