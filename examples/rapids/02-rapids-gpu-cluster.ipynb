{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T17:00:38.727567Z",
     "iopub.status.busy": "2021-10-26T17:00:38.727285Z",
     "iopub.status.idle": "2021-10-26T17:00:38.730682Z",
     "shell.execute_reply": "2021-10-26T17:00:38.730051Z",
     "shell.execute_reply.started": "2021-10-26T17:00:38.727541Z"
    }
   },
   "source": [
    "# Use RAPIDS on a GPU Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rapids and Dask Logos](https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/rapids_dask.png \"doc-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This example is an extension of the example of using [RAPIDS on a single GPU](./01-rapids-single-gpu.ipynb) to train a random forest model on NYC taxi data, only here we will be using multiple GPUs. We will be using Dask to orchestrate the model training over multiple worker machines, each with a GPU. GPU clusers can be valuable for training models quickly and can be necessary if your data is too large to fit into a single GPU's memory. \n",
    "\n",
    "We recommend you skim the single GPU example first if you haven't read it already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Compared to the first excercise, this exercise uses a few new packages.\n",
    "\n",
    "* [`dask_saturn`](https://github.com/saturncloud/dask-saturn) and [`dask_distributed`](http://distributed.dask.org/en/stable/): Set up and run the Dask cluster in Saturn Cloud.\n",
    "* [`dask-cudf`](https://docs.rapids.ai/api/cudf/stable/basics/dask-cudf.html): Create distributed `cudf` dataframes using Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client, wait\n",
    "import dask_cudf\n",
    "\n",
    "from cuml.dask.ensemble import RandomForestClassifier\n",
    "from cuml.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Dask Cluster\n",
    "\n",
    "The template resource you are running has a Dask cluster already attached to it with three workers. The `dask-saturn` code below creates two important objects: a cluster and a client.\n",
    "\n",
    "* `cluster`: knows about and manages the scheduler and workers\n",
    "    - can be used to create, resize, reconfigure, or destroy those resources\n",
    "    - knows how to communicate with the scheduler, and where to find logs and diagnostic dashboards\n",
    "* `client`: tells the cluster to do things\n",
    "    - can send work to the cluster\n",
    "    - can restart all the worker processes\n",
    "    - can send data to the cluster or pull data back from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 3\n",
    "cluster = SaturnCluster(n_workers=n_workers)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already started the Dask cluster on the resource page, then the code above will run much more quickly since it will not have to wait for the cluster to turn on.\n",
    "\n",
    ">**Pro tip**: Create and start the cluster in the Saturn Cloud UI before opening JupyterLab if you want to get a head start!\n",
    "\n",
    "The last command ensures the kernel waits until all the desired workers are online before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.wait_for_workers(n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Examine the Dataset\n",
    "\n",
    "The code below loads the data into a `dask-cudf` dataframe. You can interact with this data structure as if it were just a regular `cudf` dataframe, but it is actually a collection of smaller `cudf` dataframes spread across the workers in the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ").persist()\n",
    "\n",
    "wait(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many dataframe operations that you would execute on a pandas dataframe, like `.head()` and `.dtypes`, also work on a `dask-cudf` dataframe.\n",
    "\n",
    "Simple commands might take longer than you are used to. This is due to the distributed nature of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compute the length and memory usage of the dataset using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(taxi)\n",
    "memory_usage = taxi.memory_usage(deep=True).sum().compute() / 1e9\n",
    "print(f\"Num rows: {num_rows}, Memory Usage: {memory_usage} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note**: Dask is lazily evaluated. The result from a computation is not computed until you ask for it. Instead, a Dask task graph for the computation is produced. Anytime you have a Dask object and you want to get the result, call `.compute()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we say that a `dask-cudf` dataframe is a *distributed* dataframe, that means that it comprises multiple smaller `cudf` dataframes. Run the following to see how many of these pieces (called \"partitions\") there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data\n",
    "This code looks nearly identical to the code you ran in the single-node RAPIDS example. `dask-cudf` translates regular `cudf` operations into the corresponding distributed operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df: dask_cudf.DataFrame) -> dask_cudf.DataFrame:\n",
    "\n",
    "    df = df[df[\"fare_amount\"] > 0]  # to avoid a divide by zero error\n",
    "    df[\"tip_fraction\"] = df[\"tip_amount\"] / df[\"fare_amount\"]\n",
    "    df[\"target\"] = df[\"tip_fraction\"] > 0.2\n",
    "\n",
    "    df[\"pickup_weekday\"] = df[\"tpep_pickup_datetime\"].dt.weekday\n",
    "    df[\"pickup_hour\"] = df[\"tpep_pickup_datetime\"].dt.hour\n",
    "    df[\"pickup_week_hour\"] = (df[\"pickup_weekday\"] * 24) + df.pickup_hour\n",
    "    df[\"pickup_minute\"] = df[\"tpep_pickup_datetime\"].dt.minute\n",
    "\n",
    "    df = df[\n",
    "        [\n",
    "            \"pickup_weekday\",\n",
    "            \"pickup_hour\",\n",
    "            \"pickup_week_hour\",\n",
    "            \"pickup_minute\",\n",
    "            \"passenger_count\",\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"target\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df = df.astype(\"float32\").fillna(-1)\n",
    "    df[\"target\"] = df[\"target\"].astype(\"int32\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = prep_df(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a binary classification task, before proceeding we should examine the proportion of 1s and 0s in the target. Note that we add `.compute()` to ask for the results of the calculation immediately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi[\"target\"].value_counts(normalize=True).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataframe has been processed, let's check its length and size in memory again. Again, we need to add `.compute()` in order to get the results immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(taxi)\n",
    "memory_usage = taxi.memory_usage(deep=True).sum().compute() / 1e9\n",
    "print(f\"Num rows: {num_rows}, Memory Usage: {memory_usage} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Random Forest Model\n",
    "\n",
    "Now that the data has been prepped, it's time to build a model! This code is identical to the first example, except we are using the Dask version of the `cuml RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = taxi.drop(columns=[\"target\"])\n",
    "y = taxi[\"target\"]\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, n_streams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, this model takes less time to run than the single GPU example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics on a Test Set \n",
    "\n",
    "We will use another month of taxi data for the test set and calculate the AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-02.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ").persist()\n",
    "\n",
    "wait(taxi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test = prep_df(taxi_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of this writing, `cuml.metrics.roc_auc_score` does not support Dask collections as inputs. The code below uses `.compute()` to create `cudf` series instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = taxi_test.drop(columns=[\"target\"])\n",
    "y_test = taxi_test[\"target\"]\n",
    "\n",
    "preds = rfc.predict_proba(X_test)[1]\n",
    "\n",
    "y_test = y_test.compute()\n",
    "preds = preds.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test.to_array(), preds.to_array())\n",
    "\n",
    "plt.rcParams[\"font.size\"] = \"16\"\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "plt.plot(fpr, tpr, color=\"red\")\n",
    "plt.legend([\"Random chance\", \"ROC curve\"])\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.fill_between(fpr, tpr, color=\"yellow\", alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By only changing a few lines of code, we went from training on a single GPU to a training on a GPU cluster! Wow! \n",
    "\n",
    "Feel free to play around with parameters and the volume of data. You could, for instance, read in and train on all of 2019's taxi data (`yellow_tripdata_2019-*.csv`). *Make sure you test on a different test set!*\n",
    "\n",
    "Take a look at our other [examples](https://saturncloud.io/docs/examples/) for more resources on running models on single and multiple GPUs!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c30809920022c12dc34b6aa5982c47acf3f18a4dd3ede4f803889865384c7fa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
