{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU Clusters for Deep Learning Inference\n",
    "\n",
    "This demo is meant to show new users how you can get use Dask and GPUs on Saturn Cloud to do fast deep learning inference with your Pytorch based machine learning models. For this example, we'll use an image classification project identifying dog breeds.\n",
    "\n",
    "### What you'll learn here:\n",
    "\n",
    "* How to do inference with Pytorch on a prebuilt model\n",
    "* How to manage resources on your GPU cluster for deep learning inference tasks\n",
    "* How to run many inference tasks with Pytorch on the GPU cluster\n",
    "* How to use batch processing to accelerate your inference tasks with Pytorch on the GPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait, progress\n",
    "import time\n",
    "import dask\n",
    "from dask import persist, delayed, compute\n",
    "import dask_saturn\n",
    "from dask_saturn import SaturnCluster\n",
    "import dask.dataframe as dd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import tensorflow as tf\n",
    "\n",
    "import toolz\n",
    "import graphviz\n",
    "import re\n",
    "from PIL import Image\n",
    "to_pil = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point to Data\n",
    "\n",
    "Our dataset is housed in s3, including the labels for resnet, which we'll be using as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import tarfile\n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "s3path = 's3://dask-datasets/dogs/Images'\n",
    "s3fpath = f'{s3path}/*/*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First things first- we need to set up a GPU cluster and confirm all resources are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SaturnCluster(n_workers = 4, scheduler_size = 'g4dn4xlarge', worker_size = 'g4dn8xlarge')\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.wait_for_workers(n_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet tells us that the cluster is operable and has GPU capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(lambda: torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here then we'll set the \"device\" to always be cuda, so we can use those GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image Example\n",
    "\n",
    "Run model on a single image to test pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "with s3.open('s3://dask-datasets/dogs/imagenet1000_clsidx_to_labels.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "with s3.open(\"s3://dask-datasets/dogs/2-dog.jpg\", 'rb') as f:\n",
    "    img = Image.open(f).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(250), \n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = transform(img)\n",
    "batch_t = torch.unsqueeze(img_t, 0)\n",
    "image = to_pil(img_t)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.unsqueeze(img_t, 0)\n",
    "resnet.eval()\n",
    "out = resnet(batch_t)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "out = resnet(batch_t)\n",
    "_, indices = torch.sort(out, descending=True)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "[(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovely! Our dog is easily identified by Resnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Dataset Example\n",
    "\n",
    "Now we can try this same workflow on a large set of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Few Tips\n",
    "\n",
    "So, if you are going to run any processes on the cluster, you need all your objects over there - this lets your workers do all the tasks without reaching out to other workers or the client. However, if you use a functional setup (as we are going to do later) you'll need to do this INSIDE your function. Our architecture below will have all that written in. But before we go too complex, we should learn how that works in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command is all you need to move an object (a model, an image, etc) to the cluster. So here's how we do it with the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's how we do it with an image. (Already processed to tensor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = img_t.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now we are ready to proceed with our batch dog identification! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Process Inference with Futures\n",
    "\n",
    "In this first example, the pipeline runs in parallel for each image. This approach allows you to use very standard pythonic code and not think too much about the cluster - you write your code to accept an image path, and then it will output the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def process_one(path, fs=__builtins__):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(250), \n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    with fs.open(path, 'rb') as f:\n",
    "        img = Image.open(f).convert(\"RGB\")\n",
    "        nvis = transform(img)\n",
    "\n",
    "    truth = re.search('dogs/Images/n[0-9]+-([^/]+)/n[0-9]+_[0-9]+.jpg', path).group(1)\n",
    "    name = re.search('dogs/Images/n[0-9]+-[a-zA-Z-_]+/(n[0-9]+_[0-9]+).jpg', path).group(1)\n",
    "    \n",
    "    return [name, nvis, truth]\n",
    "\n",
    "def evaluate_pred(batch, gtruth, classes):\n",
    "    ''' Accepts images, returns human readable predictions. '''\n",
    "    _, indices = torch.sort(batch, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(batch, dim=1)[0] * 100\n",
    "    pred = [(classes[idx], percentage[idx].item()) for idx in indices[0]]\n",
    "    labs = gtruth\n",
    "    return(pred[:1], labs)\n",
    "\n",
    "def get_truth_name(name):\n",
    "    ''' Transforms the ground truth name to remove unwanted numeric prefix. '''\n",
    "    x = re.search('^[^_]*-(.*)$', name).group(1)\n",
    "    return(x)\n",
    "\n",
    "def is_match(la, ev):\n",
    "    ''' Evaluate human readable prediction against ground truth. \n",
    "    (Used in both methods)'''\n",
    "    if re.search(la.replace('_', ' '), str(ev).replace('_', ' ')):\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    return(match)     \n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def run_batch_pipeline(iteritem):\n",
    "    ''' Accepts iterable result of preprocessing, generates inferences and evaluates. '''\n",
    "    \n",
    "    with s3.open('s3://dask-datasets/dogs/imagenet1000_clsidx_to_labels.txt') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "  \n",
    "    names, images, truelabels = iteritem\n",
    "    img_t = torch.unsqueeze(images, 0)\n",
    "    with torch.no_grad():\n",
    "        # Set up model\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        resnet = resnet.to(device)\n",
    "        resnet.eval()\n",
    "\n",
    "        # run model on batch\n",
    "        img_t = img_t.to(device)\n",
    "        pred_batch = resnet(img_t)\n",
    "\n",
    "        #Evaluate batch\n",
    "        preds, labslist = evaluate_pred(pred_batch, truelabels, classes)\n",
    "\n",
    "        #Organize prediction results\n",
    "        predicted = preds\n",
    "        groundtruth = labslist\n",
    "        name = names\n",
    "        match = is_match(groundtruth, predicted)\n",
    "\n",
    "        outcome = (name, groundtruth, predicted, match)\n",
    "        \n",
    "        return(outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we map the function to all the file paths for all the images, and distribute tasks across cluster in the form of futures. The `.gather()` step will compute those futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lists = [process_one(x, fs=s3) for x in s3.glob(s3fpath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures1 = client.map(run_batch_pipeline, lists)\n",
    "result1 = client.gather(futures1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r1 = client.compute(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test1b = [x.result() for x in r1[:5000]]\n",
    "# test1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process Batches of Inferences\n",
    "\n",
    "This approach uses a similar technique but lets us distribute tasks across nodes more efficiently. This will dramatically accelerate the process, but requires a little more work adapting the code to accepting batches of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def process_one(path, fs=__builtins__):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(250), \n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    try:\n",
    "        with fs.open(path, 'rb') as f:\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "            nvis = transform(img)\n",
    "    except:\n",
    "        nvis = path\n",
    "    truth = re.search('dogs/Images/n[0-9]+-([^/]+)/n[0-9]+_[0-9]+.jpg', path).group(1)\n",
    "    name = re.search('dogs/Images/n[0-9]+-[a-zA-Z-_]+/(n[0-9]+_[0-9]+).jpg', path).group(1)\n",
    "    \n",
    "    return [name, nvis, truth]\n",
    "\n",
    "@dask.delayed\n",
    "def reformat(batch):\n",
    "    flat_list = [item for item in batch]\n",
    "    tensors = [x[1] for x in flat_list]\n",
    "    names = [x[0] for x in flat_list]\n",
    "    labels = [x[2] for x in flat_list]\n",
    "    return [names, tensors, labels]\n",
    "\n",
    "def evaluate_pred_batch(batch, gtruth, classes):\n",
    "    ''' Accepts batch of images, returns human readable predictions. '''\n",
    "    _, indices = torch.sort(batch, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(batch, dim=1)[0] * 100\n",
    "    \n",
    "    preds = []\n",
    "    labslist = []\n",
    "    for i in range(len(batch)):\n",
    "        pred = [(classes[idx], percentage[idx].item()) for idx in indices[i][:1]]\n",
    "        preds.append(pred)\n",
    "\n",
    "        labs = gtruth[i]\n",
    "        labslist.append(labs)\n",
    "        \n",
    "    return(preds, labslist)\n",
    "\n",
    "def get_truth_name(name):\n",
    "    ''' Transforms the ground truth name to remove unwanted numeric prefix. '''\n",
    "    x = re.search('^[^_]*-(.*)$', name).group(1)\n",
    "    return(x)\n",
    "\n",
    "def is_match(la, ev):\n",
    "    ''' Evaluate human readable prediction against ground truth. \n",
    "    (Used in both methods)'''\n",
    "    if re.search(la.replace('_', ' '), str(ev).replace('_', ' ')):\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    return(match)\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def run_batch_pipeline(iteritem):\n",
    "    ''' Accepts iterable result of preprocessing, generates inferences and evaluates. '''\n",
    "    \n",
    "    with s3.open('s3://dask-datasets/dogs/imagenet1000_clsidx_to_labels.txt') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "  \n",
    "    names, images, truelabels = iteritem\n",
    "    images = torch.stack(images)\n",
    "    with torch.no_grad():\n",
    "        # Set up model\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        resnet = resnet.to(device)\n",
    "        resnet.eval()\n",
    "\n",
    "        # run model on batch\n",
    "        images = images.to(device)\n",
    "        pred_batch = resnet(images)\n",
    "\n",
    "        #Evaluate batch\n",
    "        preds, labslist = evaluate_pred_batch(pred_batch, truelabels, classes)\n",
    "\n",
    "        #Organize prediction results\n",
    "        results = []\n",
    "        for j in range(0, len(images)):\n",
    "            predicted = preds[j]\n",
    "            groundtruth = labslist[j]\n",
    "            name = names[j]\n",
    "            match = is_match(groundtruth, predicted)\n",
    "\n",
    "            outcome = (name, groundtruth, predicted, match)\n",
    "            results.append(outcome)\n",
    "        \n",
    "        return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_breaks = [list(batch) for batch in toolz.partition_all(60, s3.glob(s3fpath))]\n",
    "lists2 = [[process_one(x, fs=s3) for x in y] for y in batch_breaks]\n",
    "refactored2 = [reformat(result) for result in lists2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures2 = client.map(run_batch_pipeline, refactored2)\n",
    "test2 = client.gather(futures2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look how much faster we made the job! That's the kind of thing that Dask and GPUs can make possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final2 = compute(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model's performance\n",
    "\n",
    "The two methods should return the same results, and we can test to prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pups1=test1\n",
    "\n",
    "print(f'Number of dog photos examined: {len(pups1)}')\n",
    "\n",
    "accurate = [x[3] for x in pups1 if x[3] == True]\n",
    "print(f'Number of dogs classified correctly: {len(accurate)}')\n",
    "\n",
    "pct_cor = (len(accurate)/len(pups1))*100 \n",
    "print(f'The percent of dogs classified correctly: {round(pct_cor,3)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For batch\n",
    "pups2 = final2[0]\n",
    "\n",
    "# puplen = sum([len(x) for x in pups2]) \n",
    "puplen = [y for x in pups2 for y in x]\n",
    "print(f'Number of dog photos examined: {len(puplen)}')\n",
    "accurate = [y for x in pups2 for y in x if y[3] == True]\n",
    "\n",
    "print(f'Number of dogs classified correctly: {len(accurate)}')\n",
    "\n",
    "pct_cor = (len(accurate)/len(puplen))*100 \n",
    "print(f'The percent of dogs classified correctly: {round(pct_cor,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pups1[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! You'll notice that the cases where the model is wrong are often low likelihood percentages as well, which is what we would expect to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "The last thing we want to do, then, is save our results to S3 for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in test3 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for item in flat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = pd.DataFrame(flat_list)\n",
    "flist.to_csv(\"test/dog_model_results.csv\", index = False, header = ['ground_truth','prediction','evaluation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.put('/home/jovyan/project/test/dog_model_results.csv', 's3://dask-datasets/dogs/dog_model_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
