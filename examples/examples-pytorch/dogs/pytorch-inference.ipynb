{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU Clusters for Deep Learning Inference\n",
    "\n",
    "This demo is meant to show new users how you can get use Dask and GPUs on Saturn Cloud to do fast deep learning inference with your Pytorch based machine learning models. For this example, we'll use an image classification project identifying dog breeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait, progress\n",
    "import time\n",
    "import dask\n",
    "from dask import persist, delayed, compute\n",
    "import dask_saturn\n",
    "from dask_saturn import SaturnCluster\n",
    "import dask.dataframe as dd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import toolz\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import s3fs\n",
    "import graphviz\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First things first- we need to set up a GPU cluster and confirm all resources are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SaturnCluster()\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(3)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet tells us that the cluster is operable and has GPU capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(lambda: torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def preprocess(path, fs=__builtins__):\n",
    "    '''Ingest images directly from S3, apply transformations,\n",
    "    and extract the ground truth and image identifier. Accepts\n",
    "    a filepath. '''\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(250), \n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    with fs.open(path, 'rb') as f:\n",
    "        img = Image.open(f).convert(\"RGB\")\n",
    "        nvis = transform(img)\n",
    "\n",
    "    truth = re.search('dogs/Images/n[0-9]+-([^/]+)/n[0-9]+_[0-9]+.jpg', path).group(1)\n",
    "    name = re.search('dogs/Images/n[0-9]+-[a-zA-Z-_]+/(n[0-9]+_[0-9]+).jpg', path).group(1)\n",
    "    \n",
    "    return [name, nvis, truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3fpath = 's3://saturn-public-data/dogs/Images/*/*.jpg'\n",
    "batch_breaks = [list(batch) for batch in toolz.partition_all(80, s3.glob(s3fpath))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batches = [[preprocess(x, fs=s3) for x in y] for y in batch_breaks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def reformat(batch):\n",
    "    flat_list = [item for item in batch]\n",
    "    tensors = [x[1] for x in flat_list]\n",
    "    names = [x[0] for x in flat_list]\n",
    "    labels = [x[2] for x in flat_list]\n",
    "    \n",
    "    tensors = torch.stack(tensors).to(device)\n",
    "    \n",
    "    return [names, tensors, labels]\n",
    "\n",
    "image_batches = [reformat(result) for result in image_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pred_batch(batch, gtruth, classes):\n",
    "    ''' Accepts batch of images, returns human readable predictions. '''\n",
    "    \n",
    "    _, indices = torch.sort(batch, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(batch, dim=1)[0] * 100\n",
    "    \n",
    "    preds = []\n",
    "    labslist = []\n",
    "    for i in range(len(batch)):\n",
    "        pred = [(classes[idx], percentage[idx].item()) for idx in indices[i][:1]]\n",
    "        preds.append(pred)\n",
    "\n",
    "        labs = gtruth[i]\n",
    "        labslist.append(labs)\n",
    "        \n",
    "    return(preds, labslist)\n",
    "\n",
    "def is_match(label, pred):\n",
    "    ''' Evaluates human readable prediction against ground truth.'''\n",
    "    if re.search(label.replace('_', ' '), str(pred).replace('_', ' ')):\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    return(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def run_batch_to_s3(iteritem):\n",
    "    ''' Accepts iterable result of preprocessing, generates\n",
    "    inferences and evaluates. '''\n",
    "  \n",
    "    names, images, truelabels = iteritem\n",
    "    \n",
    "    with s3.open('s3://saturn-public-data/dogs/imagenet1000_clsidx_to_labels.txt') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Retrieve, set up model\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    resnet = resnet.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        resnet.eval()\n",
    "        pred_batch = resnet(images)\n",
    "        \n",
    "        #Evaluate batch\n",
    "        preds, labslist = evaluate_pred_batch(pred_batch, truelabels, classes)\n",
    "\n",
    "        #Organize prediction results\n",
    "        outcomes = []\n",
    "        for j in range(0, len(images)):\n",
    "            match = is_match(labslist[j], preds[j])            \n",
    "            outcome = {'name': names[j], 'ground_truth': labslist[j], \n",
    "                       'prediction': preds[j], 'evaluation': match}\n",
    "            outcomes.append(outcome)\n",
    "    \n",
    "        return(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "futures = client.map(run_batch_to_s3, image_batches) \n",
    "futures_gathered = client.gather(futures)\n",
    "futures_computed = client.compute(futures_gathered, sync=False)\n",
    "\n",
    "import logging\n",
    "\n",
    "results = []\n",
    "errors = []\n",
    "for fut in futures_computed:\n",
    "    try:\n",
    "        result = fut.result()\n",
    "    except Exception as e:\n",
    "        errors.append(e)\n",
    "        logging.error(e)\n",
    "    else:\n",
    "        results.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = run_batch_to_s3(image_batches[0])\n",
    "test_sample.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_preds = [x['evaluation'] for x in results if x['evaluation'] == True]\n",
    "false_preds = [x['evaluation'] for x in results if x['evaluation'] == False]\n",
    "len(true_preds)/len(results)*100\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}