{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Many PyTorch Models Concurrently with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38660dcd",
   "metadata": {},
   "source": [
    "![PyTorch and Dask logos](https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/pytorch-dask-logos.png \"doc-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd8678",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This example shows how to train multiple neural networks in parallel using Dask. This is valuable for situations such as when you want to compare different parameters for a model to see which performs better. By having a cluster of machines each training a model, you can train all of the models more quickly.\n",
    "\n",
    "This example builds on the [introduction to PyTorch with GPU on Saturn Cloud](./01-pytorch-gpu.ipynb) example that trains a neural network to generate pet names, but instead of training the model once it trains it several times with different parameters and compares the results. Rather than having to wait for each of the different set of parameters to train sequentially, it uses the Dask cluster to train them all concurrently, dramatically speeding up the process. The code to set up the data and model architecture is the same as the original getting started with PyTorch example.\n",
    "\n",
    "The model uses LSTM layers which are especially good at discovering patterns in sequences like text. The model takes a partially complete name and determines the probability of each possible next character in the name. Characters are randomly sampled from this distribution and added to the partial name until a stop character is generated and full name has been created. For more detail about the network design and use case, see our [Saturn Cloud blog post](https://saturncloud.io/blog/dask-with-gpus/) which uses the same network architecture.\n",
    "\n",
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c3de4",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This code uses PyTorch and Dask together, and thus both libraries have to be imported. In addition, the `dask_saturn` package provides methods to work with a Saturn Cloud dask cluster, and `dask_pytorch_ddp` provides helpers when training a PyTorch model on Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7172042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "import dask\n",
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "from distributed.worker import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cbda5a",
   "metadata": {},
   "source": [
    "### Preparing data\n",
    "\n",
    "This code is used to get the data in the proper format in an easy to use class.\n",
    "\n",
    "First, download the data and create the character dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58723cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\n",
    "    \"https://saturn-public-data.s3.us-east-2.amazonaws.com/examples/pytorch/seattle_pet_licenses_cleaned.json\"\n",
    ") as f:\n",
    "    pet_names = json.loads(f.read().decode(\"utf-8\"))\n",
    "\n",
    "# Our list of characters, where * represents blank and + represents stop\n",
    "characters = list(\"*+abcdefghijklmnopqrstuvwxyz-. \")\n",
    "str_len = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222ccaf",
   "metadata": {},
   "source": [
    "Next, create a function that will take the pet names and turn them into the formatted tensors. The [Saturn Cloud blog post](https://saturncloud.io/blog/dask-with-gpus/) goes into more detail on the logic behind how to format the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_training_data(pet_names, device=None):\n",
    "    def get_substrings(in_str):\n",
    "        # add the stop character to the end of the name, then generate all the partial names\n",
    "        in_str = in_str + \"+\"\n",
    "        res = [in_str[0:j] for j in range(1, len(in_str) + 1)]\n",
    "        return res\n",
    "\n",
    "    pet_names_expanded = [get_substrings(name) for name in pet_names]\n",
    "    pet_names_expanded = [item for sublist in pet_names_expanded for item in sublist]\n",
    "    pet_names_characters = [list(name) for name in pet_names_expanded]\n",
    "    pet_names_padded = [name[-(str_len + 1) :] for name in pet_names_characters]\n",
    "    pet_names_padded = [\n",
    "        list((str_len + 1 - len(characters)) * \"*\") + characters for characters in pet_names_padded\n",
    "    ]\n",
    "    pet_names_numeric = [[characters.index(char) for char in name] for name in pet_names_padded]\n",
    "\n",
    "    # the final x and y data to use for training the model. Note that the x data needs to be one-hot encoded\n",
    "    if device is None:\n",
    "        y = torch.tensor([name[1:] for name in pet_names_numeric])\n",
    "        x = torch.tensor([name[:-1] for name in pet_names_numeric])\n",
    "    else:\n",
    "        y = torch.tensor([name[1:] for name in pet_names_numeric], device=device)\n",
    "        x = torch.tensor([name[:-1] for name in pet_names_numeric], device=device)\n",
    "    x = torch.nn.functional.one_hot(x, num_classes=len(characters)).float()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73649132",
   "metadata": {},
   "source": [
    "Finally, create a PyTorch data class to manage the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OurDataset(Dataset):\n",
    "    def __init__(self, pet_names, device=None):\n",
    "        self.x, self.y = format_training_data(pet_names, device)\n",
    "        self.permute()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.permutation[idx]\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def permute(self):\n",
    "        self.permutation = torch.randperm(len(self.x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model architecture\n",
    "\n",
    "This class defines the LSTM structure that the neural network will use;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=len(characters),\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=4,\n",
    "            batch_first=True,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, len(characters))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, state = self.lstm(x)\n",
    "        logits = self.fc(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training multiple models in parallel\n",
    "\n",
    "Below is the code to train the model multiple times concurrently in a distributed way using Dask. The code will start the Dask cluster connected to the Jupyter server Saturn Cloud resource, and wait for the right number of workers to be ready. You can make it take less time by starting the cluster via the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 3\n",
    "cluster = SaturnCluster(n_workers=n_workers)\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to run the model multiple times in parallel starts with a training function that is extremely similar to the training function without Dask. The changes are:\n",
    "\n",
    "* The function has a @dask.delayed indicator at the top so Dask knows to parallelize it\n",
    "* The training function now has an input parameter `experiment` which is a tuple containing the batch size and learning rate\n",
    "* Instead of printing the results, we now pass them to `logger.info()` so that they [show up in the Dask logs](https://saturncloud.io/docs/examples/dask/logging_in_dask/).\n",
    "* Instead of saving the actual model, we create an array of results that the model returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def train(experiment):\n",
    "    num_epochs = 8\n",
    "    batch_size, lr = experiment\n",
    "    training_start_time = datetime.datetime.now()\n",
    "    device = torch.device(0)\n",
    "\n",
    "    dataset = OurDataset(pet_names, device=device)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        dataset.permute()\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            batch_y_pred = model(batch_x)\n",
    "\n",
    "            loss = criterion(batch_y_pred.transpose(1, 2), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            logger.info(\n",
    "                f\"{datetime.datetime.now().isoformat()} - batch {i} - batch_size {batch_size} - lr {lr} - epoch {epoch} complete - loss {loss.item()}\"\n",
    "            )\n",
    "        new_results = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lr\": lr,\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"elapsed_time_sec\": (datetime.datetime.now() - training_start_time).total_seconds(),\n",
    "        }\n",
    "        results.append(new_results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the parallel code\n",
    "\n",
    "The code is executed across multiple machines by running the cell below. It takes the list of (batch size, learning rate) tuples and passes them to the Dask map function, that get combined into a single result with gather and compute. Since Dask is lazy, the computation doesn't actually begin until you run the last line of the cell and request the results. You won't see any messages show up as the model is being trained since all of the output is [captured in the Dask logs](https://saturncloud.io/docs/examples/dask/logging_in_dask/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [(4096, 0.001), (16384, 0.001), (4096, 0.01), (16384, 0.01)]\n",
    "\n",
    "train_future = client.map(train, inputs)\n",
    "futures_gathered = client.gather(train_future)\n",
    "futures_computed = client.compute(futures_gathered)\n",
    "results = [x.result() for x in futures_computed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the results\n",
    "\n",
    "This last code chunk generates several Seaborn plots of the results of the experiment. With this particular experiment the smallest batch size with highest learning rate quickly convered on a solution with fewer epochs than the other sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_concatenated = [item for sublist in results for item in sublist]\n",
    "results_df = pd.DataFrame.from_dict(results_concatenated)\n",
    "results_df[\"experiment\"] = (\n",
    "    \"bs=\" + results_df[\"batch_size\"].astype(str) + \" lr=\" + results_df[\"lr\"].astype(str)\n",
    ")\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.relplot(data=results_df, x=\"epoch\", y=\"loss\", col=\"experiment\", kind=\"line\")\n",
    "\n",
    "sns.relplot(data=results_df, x=\"elapsed_time_sec\", y=\"loss\", col=\"experiment\", kind=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/pytorch-dask-experiment-output.png\" width = 600px alt=\"Experimental results from PyTorch\" class=\"doc-image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67039076",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "With this you can now train many PyTorch GPU neural networks at the same time using Dask on Saturn Cloud. If you want to use a Dask cluster to instead train a single neural network across all of the workers, see our [related example](./03-pytorch-gpu-dask-single-model.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
