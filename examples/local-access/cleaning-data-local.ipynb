{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use External Dask Cluster from Local Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, you'll learn how to create and interact with a Dask cluster from your local environment using the Saturn Cloud service. This allows you to skip interacting with the Saturn Cloud UI almost entirely, if you want to.\n",
    "\n",
    "While we're using Jupyter locally to demonstrate, you can apply this technique for scripting or other kinds of ML workflows. \n",
    "\n",
    "<img src=\"dask-cluster.png\" width = 500px>\n",
    "\n",
    "As this diagram illustrates, the pieces in the gray box constitute the cluster, and that's what will be hosted on Saturn Cloud. Instead of the pink box (the Client) being a Jupyter instance also on Saturn Cloud, this will be your local machine.\n",
    "\n",
    "\n",
    "> This tutorial does not go into great detail about the underlying concepts of Dask, but we have [reference material for those who need more information](https://www.saturncloud.io/docs/reference/dask_concepts/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Connection to Saturn Cloud\n",
    "\n",
    "***\n",
    "\n",
    "The API Token used below (kept in `config.json`) is your user token, which you can retrieve at `https://app.community.saturnenterprise.io/api/user/token` (or fill in the prefix that represents your enterprise account URL).\n",
    "\n",
    "> **Protect your token, as it allows access to your account!**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load token\n",
    "import json\n",
    "\n",
    "with open('config.json') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Saturn Cloud\n",
    "from saturn_client import SaturnConnection\n",
    "\n",
    "saturn_connection = SaturnConnection(\n",
    "    url='https://app.community.saturnenterprise.io', \n",
    "    api_token=data['api_token']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<saturn_client.core.SaturnConnection at 0x110b48d90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saturn_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Project (if needed)\n",
    "\n",
    "If you haven't set up a project inside Saturn Cloud, you can do that programmatically from here. If you have already set up the project, you need to know the `project_id`, which you can grab from the project URL.\n",
    "\n",
    "Here, the project_id is `1133af4131124f3bb13bda367eba2b52`.\n",
    "\n",
    "Notice that it will create a new project if you run the commented-out next chunk, even if a project by that name is already in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"project_id.png\" width=750 alt=\"screenshot of project ID\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project = saturn_connection.create_project(\n",
    "#      name=\"external-demo\",\n",
    "#      image_uri='saturncloud/saturn:2021.02.22',\n",
    "#  )\n",
    "# project_id = project['id']\n",
    "# project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = '9cb3f1c325ee4f4f9a81193fac40a2ca'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Project\n",
    "\n",
    "Now, you will create an External Connection to this project, allowing you to interact with it from this notebook. Your user token is again required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask_saturn.external.ExternalConnection at 0x1126eb6d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_saturn.external import ExternalConnection\n",
    "from dask_saturn import SaturnCluster\n",
    "import dask_saturn\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "conn = ExternalConnection(\n",
    "    project_id=project_id,\n",
    "    base_url='https://app.community.saturnenterprise.io',\n",
    "    saturn_token=data['api_token']\n",
    ")\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Cluster\n",
    "\n",
    "Finally, you are ready to set up a cluster in this project! You'll see info messages logging here until the cluster is started and ready to use.\n",
    "\n",
    "If you have a cluster already created on the project, here you can just start it up without creating a new one, using this same code. You can also ask it to change size using `cluster.scale()`. For more details, we have [documentation about managing clusters](https://www.saturncloud.io/docs/getting-started/create_cluster/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dask-saturn:Starting cluster. Status: pending\n",
      "INFO:dask-saturn:Starting cluster. Status: pending\n",
      "INFO:dask-saturn:Starting cluster. Status: pending\n",
      "INFO:dask-saturn:Starting cluster. Status: pending\n",
      "INFO:dask-saturn:Starting cluster. Status: pending\n",
      "INFO:dask-saturn:Starting cluster. Status: pending\n",
      "INFO:dask-saturn:Cluster is ready\n",
      "INFO:dask-saturn:Registering default plugins\n",
      "INFO:dask-saturn:{}\n"
     ]
    }
   ],
   "source": [
    "cluster = SaturnCluster(\n",
    "    external_connection=conn,\n",
    "    n_workers=4,\n",
    "    worker_size='8xlarge',\n",
    "    scheduler_size='2xlarge',\n",
    "    nthreads=32,\n",
    "    worker_is_spot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(I have Python 3.8 locally, while the cluster is using 3.7, and the system will warn me, but this isn't going to be a problem here. This is the sort of thing you might encounter yourself when mixing local and Saturn environments.)*\n",
    "\n",
    "After this point, you can use this cluster as you might use any other. Here, I will load data from my local environment, convert it to a Dask distributed data object, and manipulate it with my cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Client Object\n",
    "\n",
    "This lets us connect from our local environment to this new cluster, and when we call the object it gives us a link to the Dask Dashboard for that cluster. We can watch at this link to see how the cluster is behaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tls://d-steph-external-demo-8692d7c816bf47e2a2d34baba0dde817.community.saturnenterprise.io:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='https://d-steph-external-demo-8692d7c816bf47e2a2d34baba0dde817.community.saturnenterprise.io' target='_blank'>https://d-steph-external-demo-8692d7c816bf47e2a2d34baba0dde817.community.saturnenterprise.io</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>128</li>\n",
       "  <li><b>Memory: </b>1.02 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.169.67:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/distributed/client.py:1129: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+---------------+----------------+----------------+\n",
      "| Package | client        | scheduler      | workers        |\n",
      "+---------+---------------+----------------+----------------+\n",
      "| numpy   | 1.19.5        | 1.20.1         | 1.20.1         |\n",
      "| python  | 3.8.6.final.0 | 3.7.10.final.0 | 3.7.10.final.0 |\n",
      "+---------+---------------+----------------+----------------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client.wait_for_workers(4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "At this point, we can load in our dataset, which for me is a set of just over 60 CSV files in an S3 repository. The total dataset represents more than 12 million rows of purchase records, with 23 columns. I am going to load just one file from this set for the demo.\n",
    "\n",
    "I am loading directly to Dask - however if you have a flat file in a local directory, you can very easily load into pandas here and then convert to Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "s3fpath = 's3://saturn-public-data/ia_data/ia_10.csv'\n",
    "\n",
    "iowa = dd.read_csv(\n",
    "    s3fpath,\n",
    "    parse_dates = ['Date'],\n",
    "    engine = 'python',\n",
    "    dtype={'Zip Code': 'object'},\n",
    "    error_bad_lines = False,\n",
    "    warn_bad_lines = False,\n",
    "    storage_options={'anon': True},\n",
    "    assume_missing=True\n",
    ")\n",
    "\n",
    "# Comment out below if using multiple files\n",
    "iowa = iowa.repartition(npartitions = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dask.distributed import wait\n",
    "\n",
    "iowa = iowa.persist()\n",
    "_ = wait(iowa)\n",
    "iowa.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows: CPU times: user 138 ms, sys: 16 ms, total: 154 ms\n",
    "Wall time: 1min 8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analyses\n",
    "\n",
    "To demonstrate an analysis on the cluster, I'll do a couple of analyses that you might want to run for business.\n",
    "\n",
    "The first task to do aggregations across dataframes effectively with Dask is to **set the index of the dataframe**. This lets Dask easily organize the data that is partitioned across the cluster, while still keeping it distributed. \n",
    "\n",
    "> This is sometimes a slow task, but it only needs to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iowa = iowa.set_index(\"Date\")\n",
    "iowa = iowa.persist()\n",
    "_ = wait(iowa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows: CPU times: user 549 ms, sys: 52.6 ms, total: 601 ms\n",
    "Wall time: 4min 37s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Rolling Average\n",
    "\n",
    "From here, we can treat the dataframe very much like a pandas dataframe, but it remains distributed.   \n",
    "We'll calculate a new series, which is the 30 day rolling average of items sold (bottles), then shape it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bottles_sold_roll = iowa['Bottles Sold'].rolling('30D').sum()\n",
    "bottles_sold_roll = bottles_sold_roll.to_frame(name=\"bottles_sold_roll\")\n",
    "bottles_sold_roll = bottles_sold_roll.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows: \n",
    "CPU times: user 32.1 ms, sys: 1.45 ms, total: 33.5 ms\n",
    "Wall time: 32.5 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bottles_sold_roll.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows: \n",
    "CPU times: user 7.78 ms, sys: 1.86 ms, total: 9.64 ms\n",
    "Wall time: 1.38 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and Summarize\n",
    "\n",
    "For a second example of calculations over the dataset on the cluster, I'll group by store and date, and calculate the store level daily sales in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iowa['Sale (Dollars)'] = iowa['Sale (Dollars)'].str.lstrip('$').astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows: \n",
    "CPU times: user 8.34 ms, sys: 150 µs, total: 8.49 ms\n",
    "Wall time: 8.45 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sum_store_sales = iowa.groupby(['Date', \"Store Number\"])[\"Sale (Dollars)\"].sum()\n",
    "sum_store_sales = sum_store_sales.to_frame(name=\"sum_store_sales\")\n",
    "sum_store_sales = sum_store_sales.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows: \n",
    "CPU times: user 29.1 ms, sys: 1.64 ms, total: 30.7 ms\n",
    "Wall time: 29.7 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sum_store_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows: \n",
    "CPU times: user 58.7 ms, sys: 8.11 ms, total: 66.8 ms\n",
    "Wall time: 40.1 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Dataframes\n",
    "\n",
    "If you want to, from here you can rejoin those new columns to your existing data using the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iowa_new = dd.concat([iowa, bottles_sold_roll], axis=1)\n",
    "iowa_new = iowa_new.persist()\n",
    "_ = wait(iowa_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows:\n",
    "CPU times: user 128 ms, sys: 11.2 ms, total: 139 ms\n",
    "Wall time: 29.7 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iowa_final = iowa_new.merge(sum_store_sales, how=\"left\",\n",
    "                            on=['Date', \"Store Number\"])\n",
    "iowa_final = iowa_final.persist()\n",
    "_ = wait(iowa_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows:\n",
    "CPU times: user 72.6 ms, sys: 6.27 ms, total: 78.8 ms\n",
    "Wall time: 6.52 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Data\n",
    "\n",
    "If you examine this object, you end up seeing the shape of the dataframe but not the contents - this is a function of its distributed nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iowa_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows:\n",
    "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
    "Wall time: 5.25 µs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we check the head of this object, we can see the actual values. This may take time, because part of the dataframe must be computed to show the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "iowa_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime with 12 million rows:\n",
    "CPU times: user 8.63 ms, sys: 1.94 ms, total: 10.6 ms\n",
    "Wall time: 110 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iowa_final[iowa_final['Store Number'] == 2649].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iowa_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return to pandas\n",
    "\n",
    "At this point, you can use this dataset for whatever next steps you have - that might include passing it to a machine learning workflow, for example.\n",
    "\n",
    "If you need to use the data in a way that is not Dask compatible, and the data is small enough, you can return it to a pandas dataframe with this command. Because this means all the computations are run, and the data is consolidated into the Client environment, it can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iowa_pd = iowa_final.compute()\n",
    "type(iowa_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping\n",
    "\n",
    "Because we are not working inside the UI, we want to make sure that we close down any resources when we are done- otherwise undesired costs can be incurred.\n",
    "\n",
    "To shut down the cluster entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "External Demo Py3 (demo_external)",
   "language": "python",
   "name": "demo_external"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
